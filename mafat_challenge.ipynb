{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AaZtlvVZ-2T"
   },
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJCS3oBDg9l5"
   },
   "source": [
    "##### install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 4897,
     "status": "ok",
     "timestamp": 1601059109244,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "ggG0OwZgD7pV",
    "outputId": "5f1d8415-e09e-4cde-c251-cef3ab7f05dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.6/dist-packages (0.10.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.17.8)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.10.3)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.12.4)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.0.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.1.8)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n",
      "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.6.20)\n",
      "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
      "Requirement already satisfied: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (0.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb) (50.3.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb   # run this command to insatll wandb on colab - worth it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAjkkHTGhDKC"
   },
   "source": [
    "##### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T15:01:17.881504Z",
     "start_time": "2020-08-15T15:01:09.541704Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 8325,
     "status": "ok",
     "timestamp": 1601540094770,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "kSMa29SfVfPy",
    "outputId": "8cebfcd4-2d3a-46f0-d4a4-82bf30aeb8fc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# import wandb\n",
    "# from wandb.keras import WandbCallback\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from termcolor import colored\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50, VGG19, VGG16, Xception\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seed for reproducibility of results\n",
    "seed_value = 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# Configure a new global `tensorflow` session\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 53989,
     "status": "ok",
     "timestamp": 1601540140467,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "U4CQDksDbfl_",
    "outputId": "f0747ffe-071c-4e76-f54c-1cc99989ee92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "mount_path = '/content/gdrive/'\n",
    "drive.mount(mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 3404,
     "status": "ok",
     "timestamp": 1601540149599,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "f5ZPU_OAXlFl",
    "outputId": "97a185dc-cea8-46c5-8f2a-7e80b613d4c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEverything is setup correctly\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Set and test path to competition data files\n",
    "competition_path = 'My Drive/Final Project ITC/MAFAT Challenge/Data'\n",
    "try:\n",
    "  if competition_path == 'INSERT HERE':\n",
    "    print('Please enter path to competition data files:')\n",
    "    competition_path = input()\n",
    "  file_path = 'MAFAT RADAR Challenge - Training Set V1.csv'\n",
    "  with open(f'{mount_path}/{competition_path}/{file_path}') as f:\n",
    "    f.readlines()\n",
    "  print(colored('Everything is setup correctly', color='green'))\n",
    "except:\n",
    "  print(colored('Please mount drive and set competition_path correctly',\n",
    "                color='red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXzT9M3g8BFF"
   },
   "source": [
    "## **Functions**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6nD0fkyydoF"
   },
   "source": [
    "### Loading python scripts\n",
    "\n",
    "All functions will be used in the \"Training the Model\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 948,
     "status": "ok",
     "timestamp": 1601540157582,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "oqPasUQ1x16h"
   },
   "outputs": [],
   "source": [
    "# paths for the datasets\n",
    "experiment_auxiliary_path = 'MAFAT RADAR Challenge - Auxiliary Experiment Set V2'\n",
    "synthetic_auxiliary_path = 'MAFAT RADAR Challenge - Auxiliary Synthetic Set V2'\n",
    "train_path = 'MAFAT RADAR Challenge - Training Set V1'\n",
    "test_path = 'MAFAT RADAR Challenge - Public Test Set V1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1601540158020,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "U9RdqgfBRtpV"
   },
   "outputs": [],
   "source": [
    "files_path = mount_path + \"My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar\"\n",
    "sys.path.append(files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6709,
     "status": "ok",
     "timestamp": 1601540165187,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "7GD6o1VUSdDq"
   },
   "outputs": [],
   "source": [
    "from loading_functions import load_data, load_pkl_data, load_csv_metadata, load_data_all_datasets, append_dict\n",
    "from spectogram_plots import plot_shited_spectrogram, plot_recenter_midline_spectrogram, spectrogram_cmap\n",
    "from model_roc_function import stats\n",
    "from data_augmentation import  recenter_midline, shift_spectrogram\n",
    "from data_preprocessing_funcs import data_preprocess\n",
    "from plot_learning_curve import plot_loss_and_accuracy_over_epoches\n",
    "from data_augmentation import recenter_midline, shift_spectrogram\n",
    "from full_loading_and_process import process_and_split_data\n",
    "from sampling_data import subsampling, subsampling_segments_target_ratio, balance_target, split_x_y, split_train_val\n",
    "\n",
    "\n",
    "np.save('/content/cmap.npy', spectrogram_cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HBO7W27uds6"
   },
   "source": [
    "### model configurations - dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5042,
     "status": "ok",
     "timestamp": 1601540165194,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "gPv3kAcPekEv"
   },
   "outputs": [],
   "source": [
    "model_input = {\n",
    "                'data_extraction':  {\n",
    "                                    'train_df': [4, False],  # [num segments in track, balance the data?]\n",
    "                                    'valid_df': [4, True],\n",
    "                                    'exp_df':   [2, False],\n",
    "                                    'synth_df': [1, True]\n",
    "                                    },\n",
    "                'model_conf' : {\n",
    "                              'sota_model': \"ResNet50\",\n",
    "                              'sota_model_layer': \"conv4_block1_2_conv\",\n",
    "                              'input_last_channel': 3,\n",
    "                              'batch_norm': False,\n",
    "                              'batch_size':64,\n",
    "                              'no_epochs':100,\n",
    "                              'learning_rate': 0.0005,\n",
    "                              'monitor': 'val_accuracy'\n",
    "                              },\n",
    "               'callback' : {'early_stop':{\n",
    "                                           'patience':10,\n",
    "                                           'verbose': 1\n",
    "                                          },\n",
    "                            'model_checkpoint':{\n",
    "                                                'flag':True,\n",
    "                                                'file_path':f\"{mount_path}My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models\",\n",
    "                                                'save_weights_only':False,\n",
    "                                                'verbose': 1\n",
    "                                                }\n",
    "                            },\n",
    "               'IDG' : {\n",
    "                        'vertical_flip':True,\n",
    "                        'horizontal_flip':True,\n",
    "                        'width_shift_range' : 0,\n",
    "                        'height_shift_range': 0,\n",
    "                        'fill_mode':'nearest',\n",
    "                        'brightness_range' : [1,1],\n",
    "                        'preprocessing_function' : None\n",
    "                        }        \n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-j6KvZouVfP6"
   },
   "source": [
    "### **Splitting the Training set**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QRaW4xmPNt5"
   },
   "source": [
    "The functions below split the training set into Train and Validation sets.\n",
    "\n",
    "the logic: \n",
    "\n",
    "- take the full training set and split it to train and validation according to track id and make sure to that there are no segments of the same track in the training and in the validation (similar to the approach of MAFAT)\n",
    "- To do the split in the easiest way, we will take still only geolocations 1 and 4 but this time the sampling of the segments will use the subsampling function\n",
    "\n",
    "- to the x_train we will add data from the expeirment and from the synthetic datasets, using sampling- making sure the the number will lead to balanced data between animal and humans in the end  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foTpFmn9VfP7"
   },
   "outputs": [],
   "source": [
    "# Function for splitting the data to training and validation\n",
    "# and function for selecting samples of segments from the Auxiliary dataset\n",
    "\n",
    "# function is part of the python scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "170f5Pcgk5gF"
   },
   "source": [
    "## **Model functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrGpOOCGgVdz"
   },
   "source": [
    "### **CNN Model** - transfer learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fm-o5mr6gT7i"
   },
   "outputs": [],
   "source": [
    "# Building the model\n",
    "def create_model(model_tl, init, layer, input_shape= (126, 32, 3)):\n",
    "  \"\"\"\n",
    "  Transfer learning Resnet model. trained on imagenet\n",
    "  The input shape must be RGB, hense we must duplicate the channel 3 times\n",
    "\n",
    "  Arguments:\n",
    "    input_shape -- the shape of our input\n",
    "    init -- the weight initialization\n",
    "\n",
    "  Returns:\n",
    "    CNN model - with resnet inside  \n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  transfer_learning_model = model_tl(include_top=False, weights=\"imagenet\", pooling='avg')\n",
    "\n",
    "  model_num_wandb = wandb.run.name.rsplit(\"-\")[-1]\n",
    "\n",
    "  tl_model = Sequential(name=f\"{transfer_learning_model.name}_{model_num_wandb}\")\n",
    "\n",
    "  tl_model.add(Input(shape=input_shape))\n",
    "\n",
    "  if input_shape[-1] == 1:\n",
    "    tl_model.add(Conv2D(3,(3,3),padding='same'))\n",
    "  \n",
    "  tl_model.add(Model(inputs=transfer_learning_model.input, outputs=transfer_learning_model.get_layer(layer).output, name=transfer_learning_model.name))\n",
    "\n",
    "  if model_input['model_conf']['batch_norm']:\n",
    "    tl_model.add(BatchNormalization())\n",
    "\n",
    "  tl_model.add(Flatten())\n",
    "\n",
    "  # tl_model.add(Dense(64, kernel_regularizer = 'l2', activation='relu', kernel_initializer = init))\n",
    "  # tl_model.add(Dropout(0.3))\n",
    "\n",
    "  # tl_model.add(Dense(32, kernel_regularizer = 'l2', activation='relu', kernel_initializer = init))\n",
    "  # tl_model.add(Dropout(0.15))\n",
    "  tl_model.add(Dense(1, activation='sigmoid', kernel_initializer = init))\n",
    "\n",
    "  # Say not to train first layer of the model. It is already trained\n",
    "  tl_model.layers[0].trainable = False\n",
    "\n",
    "\n",
    "  return tl_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSlzmnKh8ZMc"
   },
   "source": [
    "#### Baseline model of MAFAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_l9vQd9x8UC3"
   },
   "outputs": [],
   "source": [
    "# Building the model\n",
    "def create_model_cnn_baseline(input_shape, init):\n",
    "  \"\"\"\n",
    "  CNN model.\n",
    "\n",
    "  Arguments:\n",
    "    input_shape -- the shape of our input\n",
    "    init -- the weight initialization\n",
    "\n",
    "  Returns:\n",
    "    CNN model    \n",
    "  \"\"\"\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', kernel_initializer = init, bias_regularizer='l2', input_shape=input_shape))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer = init, bias_regularizer='l2'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128, kernel_regularizer = 'l2', activation='relu', kernel_initializer = init))\n",
    "  model.add(Dense(32, kernel_regularizer = 'l2', activation='relu', kernel_initializer = init))\n",
    "  model.add(Dense(1, activation='sigmoid', kernel_initializer = init))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVxE8IP4lzAn"
   },
   "source": [
    "## Loading the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTwpI1jd63J2"
   },
   "source": [
    "#### loading the data and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1601540166842,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "vS6JYG3LuqLE"
   },
   "outputs": [],
   "source": [
    "def load_and_split_data():\n",
    "  training_df, synthetic_auxiliary_df, experiment_auxiliary_df = load_data_all_datasets()\n",
    "  train_x, val_x, test_x, train_y, val_y, test_df  = process_and_split_data(training_df, synthetic_auxiliary_df, experiment_auxiliary_df, model_input['data_extraction'])\n",
    "  del training_df, synthetic_auxiliary_df, experiment_auxiliary_df\n",
    "  return train_x, val_x, test_x, train_y, val_y, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "executionInfo": {
     "elapsed": 186416,
     "status": "ok",
     "timestamp": 1601540377082,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "mSl2sk-4A_Oi",
    "outputId": "1b30c667-e970-4733-93c9-d956a84b2558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading and spliting the data\n",
      "[INFO] Loading Auxiliary Experiment set - can take a few minutes\n",
      "[INFO] Loading Auxiliary Synthetic set - can take a few minutes\n",
      "[INFO] Loading Train set - can take a few minutes\n",
      "exp_df 2 False\n",
      "synt_df 1 True\n",
      "train_df 4 False\n",
      "valid_df 4 True\n",
      "exp_df humans segments: 5215 0\n",
      "synt_df humans segments: 447 447\n",
      "train_df humans segments: 0 2995\n",
      "valid_df humans segments: 399 399\n",
      "[INFO] Adding segments from the experiment and Synthetic auxiliary sets to the training set\n",
      "[INFO] Preprocessing and split the data to training and validation\n",
      "[INFO] Creating 3 channels for the train and validation set\n",
      "[INFO] Loading and preprocessing public test set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9104, 126, 32, 3), (798, 126, 32, 3), (106, 126, 32, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, val_x, test_x, train_y, val_y, test_df  = load_and_split_data()\n",
    "\n",
    "if model_input['model_conf']['input_last_channel'] == 1:\n",
    "  print(\"using conv2d - one channel input\")\n",
    "  train_x = train_x[:, :, :, 1]\n",
    "  train_x = train_x.reshape(list(train_x.shape)+[1])\n",
    "\n",
    "  val_x = val_x[:, :, :, 1]\n",
    "  val_x = val_x.reshape(list(val_x.shape)+[1])\n",
    "\n",
    "  test_x = test_x[:, :, :, 1]\n",
    "  test_x = test_x.reshape(list(test_x.shape)+[1])\n",
    "\n",
    "train_x.shape, val_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 1142,
     "status": "ok",
     "timestamp": 1601541091602,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "rkvSI-8uGotO",
    "outputId": "0c6c2fbb-0dc8-49f7-8758-4a4bc96a206b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax =plt.subplots(1,2, figsize=(12,4))\n",
    "sns.countplot(train_y, ax=ax[0])\n",
    "sns.countplot(val_y, ax=ax[1])\n",
    "\n",
    "ax[0].set_title(\"train - countplot of target (human = 1)\")\n",
    "ax[1].set_title(\"validation\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByTli3H1VfQD"
   },
   "source": [
    "## **Training The Model functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYTkq4LKX2PE"
   },
   "source": [
    "#### ImageDataGenerator + model callbacks + Wandb config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zh7bWiXFOLpx"
   },
   "outputs": [],
   "source": [
    "def create_IDG(idg_input,train_x):\n",
    "  datagen = ImageDataGenerator(\n",
    "                                vertical_flip = idg_input['vertical_flip'],\n",
    "                                horizontal_flip=idg_input['horizontal_flip'],\n",
    "                                width_shift_range = idg_input['width_shift_range'],\n",
    "                                height_shift_range=idg_input['height_shift_range'],\n",
    "                                fill_mode=idg_input['fill_mode'],\n",
    "                                brightness_range = idg_input['brightness_range'],\n",
    "                                preprocessing_function = idg_input['preprocessing_function']\n",
    "                              )\n",
    "  #Fitting the Image Generator defined above to the X train data set\n",
    "  datagen.fit(train_x)\n",
    "\n",
    "  return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZZJ5xuUXhlZ"
   },
   "outputs": [],
   "source": [
    "def callbacks(model, final_model_path):\n",
    "     \n",
    "    mc = tf.keras.callbacks.ModelCheckpoint(final_model_path,\n",
    "                                            monitor= model_input['model_conf']['monitor'],\n",
    "                                            verbose= model_input['callback']['model_checkpoint']['verbose'],\n",
    "                                            save_best_only=True,\n",
    "                                            save_weights_only=False,\n",
    "                                            ) \n",
    "    earlystop = EarlyStopping(patience= model_input['callback']['early_stop']['patience'], \n",
    "                              monitor = model_input['model_conf']['monitor'],\n",
    "                              verbose = model_input['callback']['early_stop']['verbose'])\n",
    "    return mc, earlystop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baWV7oEMomga"
   },
   "source": [
    "### wandb connfig and build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCtSZK0jmA2x"
   },
   "outputs": [],
   "source": [
    "def wandb_config():\n",
    "\n",
    "  wandb.init(project=\"MAFAT\",\n",
    "            config={\n",
    "                'sota_model':        model_input['model_conf'][\"sota_model\"],\n",
    "                'sota_model_layer':  model_input['model_conf'][\"sota_model_layer\"],\n",
    "                'input_last_channel':model_input['model_conf']['input_last_channel'],\n",
    "                \"batch_size\":        model_input['model_conf'][\"batch_size\"],\n",
    "                \"no_epochs\":         model_input['model_conf'][\"no_epochs\"],\n",
    "                \"learning_rate\":     model_input['model_conf'][\"learning_rate\"],\n",
    "                \"data_extraction\":   model_input[\"data_extraction\"],\n",
    "                'batch_norm':        model_input['model_conf']['batch_norm']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuQ2cSkmp270"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  \"\"\"\n",
    "  buliding the model according to the config dict\n",
    "  important to chose sota_model, sota_model_layer, input_last_channel\n",
    "  \"\"\"\n",
    "  img_width, img_height = 126, 32\n",
    "  loss_function = BinaryCrossentropy()\n",
    "  optimizer = Adam(learning_rate = wandb.config.learning_rate)\n",
    "  init = tf.keras.initializers.GlorotNormal(seed = 0)\n",
    "  input_shape = (img_width, img_height, wandb.config.input_last_channel)  # must be 3 is RGB for using transfer learning\n",
    "\n",
    "  if wandb.config.sota_model == \"ResNet50\":\n",
    "    tl_model_build = ResNet50\n",
    "  elif wandb.config.sota_model == \"VGG19\":\n",
    "    tl_model_build = VGG19\n",
    "\n",
    "  elif wandb.config.sota_model == \"VGG16\":\n",
    "    tl_model_build = VGG16\n",
    "  elif wandb.config.sota_model == \"Xception\":\n",
    "    tl_model_build = Xception\n",
    "  \n",
    "  else:\n",
    "    print(\"No existing model has been chosen\")\n",
    "  \n",
    "  model = create_model(tl_model_build, init, wandb.config.sota_model_layer, input_shape)  \n",
    "  model.compile(loss=loss_function, optimizer=optimizer, metrics=['AUC', 'accuracy'])\n",
    "\n",
    "  folder_models_path = model_input['callback']['model_checkpoint']['file_path']\n",
    "\n",
    "  final_model_path = f'{folder_models_path}/{model.name}.h5'\n",
    "  mc, earlystop = callbacks(model, final_model_path) \n",
    "\n",
    "\n",
    "  return model, mc, earlystop, final_model_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jojU_xOsornS"
   },
   "source": [
    "### run single model, run several layers and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WjZAjB6sk0t"
   },
   "outputs": [],
   "source": [
    "def run_model(model, mc, earlystop):\n",
    "\n",
    "  datagen = create_IDG(model_input['IDG'], train_x)\n",
    "  flow = datagen.flow(train_x, train_y, batch_size=wandb.config.batch_size)\n",
    "  \n",
    "  history = model.fit(flow,\n",
    "                      steps_per_epoch=len(train_x) // wandb.config.batch_size,\n",
    "                      epochs=wandb.config.no_epochs,\n",
    "                      validation_data=(val_x, val_y),\n",
    "                      validation_steps=len(val_x) // wandb.config.batch_size,\n",
    "                      callbacks=[mc, earlystop, WandbCallback(data_type=\"image\", validation_data=(val_x, val_y))])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ak3qDQciJBR2"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve_of_models(final_model_path):\n",
    "\n",
    "  print(f\"model: {final_model_path.rsplit('/')[-1]}\")\n",
    "  final_model = tf.keras.models.load_model(final_model_path)\n",
    "  # Plot ROC curve and show ROC-AUC results of the training and validation sets. \n",
    "  pred = [final_model.predict(train_x), final_model.predict(val_x)]\n",
    "  actual = [train_y, val_y]\n",
    "  stats(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQac0KiSo4DD"
   },
   "outputs": [],
   "source": [
    "def run_several_layers(model_name, layers_list):\n",
    "  print(f\"checkin model: {model_name}\")\n",
    "  for i, output_layer in enumerate(layers_list):\n",
    "    print(f\"layer {i + 1} - {output_layer} - out of {len(layers_list)}\")\n",
    "    \n",
    "    model_input['model_conf']['sota_model'] = model_name\n",
    "    model_input['model_conf']['sota_model_layer'] = output_layer\n",
    "\n",
    "    wandb_config()\n",
    "    model, mc, earlystop, final_model_path = build_model()\n",
    "    history = run_model(model, mc, earlystop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhs6SHOQvjUW"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOfXzmPYK24k"
   },
   "source": [
    "### Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11359,
     "status": "ok",
     "timestamp": 1601038956559,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "pXlrYyKZtiuU",
    "outputId": "54d3977a-0091-4bbb-ce90-51cff07d7e56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 7885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_130010-1pqr05d2/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_130010-1pqr05d2/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdevoted-galaxy-70\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/1pqr05d2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_130225-3gntvsf9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mresilient-snowflake-71\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/3gntvsf9\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/3gntvsf9</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: \"resnet50_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, None, None, 256)   2182528   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 2,186,625\n",
      "Trainable params: 4,097\n",
      "Non-trainable params: 2,182,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_input['model_conf']['sota_model'] = \"ResNet50\"\n",
    "model_input['model_conf']['sota_model_layer'] = \"conv4_block1_2_conv\"\n",
    "\n",
    "\n",
    "# Creating and running the model\n",
    "wandb_config()\n",
    "model, mc, earlystop, final_model_path = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sgS5HnELtdt"
   },
   "source": [
    "#### running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107362,
     "status": "ok",
     "timestamp": 1601033026476,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "CVwP-bW1xfHT",
    "outputId": "d4f0b81a-4fd7-47b4-ddb4-523790898a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1714 - auc: 0.9808 - accuracy: 0.9365\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.51121, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/resnet50_56.h5\n",
      "243/243 [==============================] - 9s 36ms/step - loss: 0.1711 - auc: 0.9809 - accuracy: 0.9365 - val_loss: 0.8545 - val_auc: 0.7523 - val_accuracy: 0.5112\n",
      "Epoch 2/50\n",
      "241/243 [============================>.] - ETA: 0s - loss: 0.1109 - auc: 0.9908 - accuracy: 0.9597\n",
      "Epoch 00002: val_accuracy improved from 0.51121 to 0.69731, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/resnet50_56.h5\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 0.1109 - auc: 0.9908 - accuracy: 0.9595 - val_loss: 0.6063 - val_auc: 0.7445 - val_accuracy: 0.6973\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0993 - auc: 0.9925 - accuracy: 0.9639\n",
      "Epoch 00003: val_accuracy did not improve from 0.69731\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 0.0993 - auc: 0.9925 - accuracy: 0.9639 - val_loss: 0.6483 - val_auc: 0.7400 - val_accuracy: 0.6525\n",
      "Epoch 4/50\n",
      "241/243 [============================>.] - ETA: 0s - loss: 0.1028 - auc: 0.9921 - accuracy: 0.9644\n",
      "Epoch 00004: val_accuracy improved from 0.69731 to 0.71076, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/resnet50_56.h5\n",
      "243/243 [==============================] - 8s 32ms/step - loss: 0.1025 - auc: 0.9921 - accuracy: 0.9644 - val_loss: 0.5807 - val_auc: 0.7679 - val_accuracy: 0.7108\n",
      "Epoch 5/50\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.0934 - auc: 0.9932 - accuracy: 0.9659\n",
      "Epoch 00005: val_accuracy did not improve from 0.71076\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 0.0942 - auc: 0.9931 - accuracy: 0.9660 - val_loss: 1.0086 - val_auc: 0.7539 - val_accuracy: 0.5314\n",
      "Epoch 6/50\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.0899 - auc: 0.9937 - accuracy: 0.9683\n",
      "Epoch 00006: val_accuracy did not improve from 0.71076\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0899 - auc: 0.9937 - accuracy: 0.9681 - val_loss: 0.7293 - val_auc: 0.7631 - val_accuracy: 0.5919\n",
      "Epoch 7/50\n",
      "241/243 [============================>.] - ETA: 0s - loss: 0.0910 - auc: 0.9937 - accuracy: 0.9662\n",
      "Epoch 00007: val_accuracy did not improve from 0.71076\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 0.0910 - auc: 0.9937 - accuracy: 0.9662 - val_loss: 1.3010 - val_auc: 0.7462 - val_accuracy: 0.5135\n",
      "Epoch 8/50\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.0944 - auc: 0.9928 - accuracy: 0.9649\n",
      "Epoch 00008: val_accuracy did not improve from 0.71076\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0945 - auc: 0.9927 - accuracy: 0.9649 - val_loss: 1.4001 - val_auc: 0.7613 - val_accuracy: 0.5090\n",
      "Epoch 9/50\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.0894 - auc: 0.9936 - accuracy: 0.9678\n",
      "Epoch 00009: val_accuracy did not improve from 0.71076\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 0.0892 - auc: 0.9936 - accuracy: 0.9679 - val_loss: 2.2067 - val_auc: 0.7335 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "241/243 [============================>.] - ETA: 0s - loss: 0.0860 - auc: 0.9942 - accuracy: 0.9688\n",
      "Epoch 00010: val_accuracy did not improve from 0.71076\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0863 - auc: 0.9942 - accuracy: 0.9687 - val_loss: 1.9499 - val_auc: 0.7464 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0892 - auc: 0.9939 - accuracy: 0.9684\n",
      "Epoch 00011: val_accuracy did not improve from 0.71076\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0892 - auc: 0.9939 - accuracy: 0.9684 - val_loss: 0.7804 - val_auc: 0.7569 - val_accuracy: 0.5740\n",
      "Epoch 12/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0910 - auc: 0.9937 - accuracy: 0.9663\n",
      "Epoch 00012: val_accuracy did not improve from 0.71076\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0910 - auc: 0.9937 - accuracy: 0.9663 - val_loss: 1.0882 - val_auc: 0.7618 - val_accuracy: 0.5448\n",
      "Epoch 13/50\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.0905 - auc: 0.9940 - accuracy: 0.9684\n",
      "Epoch 00013: val_accuracy did not improve from 0.71076\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0903 - auc: 0.9940 - accuracy: 0.9684 - val_loss: 1.2050 - val_auc: 0.7555 - val_accuracy: 0.5291\n",
      "Epoch 14/50\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.0769 - auc: 0.9950 - accuracy: 0.9728\n",
      "Epoch 00014: val_accuracy did not improve from 0.71076\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 0.0767 - auc: 0.9951 - accuracy: 0.9729 - val_loss: 0.9969 - val_auc: 0.7554 - val_accuracy: 0.5516\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_resnet50 = run_model(model, mc, earlystop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mj7Trcp2OMd-"
   },
   "source": [
    "#### running a loop over several layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ByYRQ3FUWGv"
   },
   "outputs": [],
   "source": [
    "resnent50 = ResNet50(include_top=False, weights=\"imagenet\", pooling='avg')\n",
    "resnent50_last_layers = [layer.name for layer in resnent50.layers[-10:]]\n",
    "resnent50_last_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoloF3_MpTuV"
   },
   "outputs": [],
   "source": [
    "run_several_layers(\"ResNet50\", resnent50_last_layers[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1229438,
     "status": "ok",
     "timestamp": 1601038210742,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "-Mj_8XTQOPq9",
    "outputId": "625fa829-f016-4f4c-f5e3-595ff8b110ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_122749-1a8wr4jk/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_122749-1a8wr4jk/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.09535645693540573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9930832982063293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9651792645454407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 1.3968284130096436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.5529268383979797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 81\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601036953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 1.0319820642471313\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 181 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlilac-dream-59\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/1a8wr4jk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_122941-18m96fs1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrestful-field-60\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/18m96fs1\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/18m96fs1</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1776 - auc: 0.9803 - accuracy: 0.9360\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_60.h5\n",
      "243/243 [==============================] - 15s 61ms/step - loss: 0.1776 - auc: 0.9803 - accuracy: 0.9360 - val_loss: 1.2230 - val_auc: 0.6229 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1137 - auc: 0.9904 - accuracy: 0.9574\n",
      "Epoch 00002: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 13s 53ms/step - loss: 0.1137 - auc: 0.9904 - accuracy: 0.9574 - val_loss: 1.0721 - val_auc: 0.5950 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1082 - auc: 0.9910 - accuracy: 0.9596\n",
      "Epoch 00003: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 49ms/step - loss: 0.1082 - auc: 0.9910 - accuracy: 0.9596 - val_loss: 1.1712 - val_auc: 0.5825 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1043 - auc: 0.9920 - accuracy: 0.9603\n",
      "Epoch 00004: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 49ms/step - loss: 0.1043 - auc: 0.9920 - accuracy: 0.9603 - val_loss: 1.3449 - val_auc: 0.5677 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0984 - auc: 0.9925 - accuracy: 0.9631\n",
      "Epoch 00005: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 49ms/step - loss: 0.0984 - auc: 0.9925 - accuracy: 0.9631 - val_loss: 1.2366 - val_auc: 0.5789 - val_accuracy: 0.4978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_122941-18m96fs1/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_122941-18m96fs1/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.0984148383140564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.992485761642456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9631158113479614\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 1.236600637435913\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.5789177417755127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.49775785207748413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601037060\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 1.0721052885055542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 181 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mrestful-field-60\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/18m96fs1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_123100-36ku1ktq\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfancy-wood-61\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/36ku1ktq\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/36ku1ktq</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.2602 - auc: 0.9753 - accuracy: 0.9158\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.52466, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_61.h5\n",
      "243/243 [==============================] - 15s 61ms/step - loss: 0.2602 - auc: 0.9753 - accuracy: 0.9158 - val_loss: 0.7049 - val_auc: 0.6521 - val_accuracy: 0.5247\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1459 - auc: 0.9884 - accuracy: 0.9527\n",
      "Epoch 00002: val_accuracy did not improve from 0.52466\n",
      "243/243 [==============================] - 12s 48ms/step - loss: 0.1459 - auc: 0.9884 - accuracy: 0.9527 - val_loss: 0.8174 - val_auc: 0.6410 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1252 - auc: 0.9901 - accuracy: 0.9569\n",
      "Epoch 00003: val_accuracy did not improve from 0.52466\n",
      "243/243 [==============================] - 12s 49ms/step - loss: 0.1252 - auc: 0.9901 - accuracy: 0.9569 - val_loss: 0.8900 - val_auc: 0.6311 - val_accuracy: 0.5045\n",
      "Epoch 4/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1142 - auc: 0.9916 - accuracy: 0.9610\n",
      "Epoch 00004: val_accuracy did not improve from 0.52466\n",
      "243/243 [==============================] - 12s 48ms/step - loss: 0.1150 - auc: 0.9914 - accuracy: 0.9608 - val_loss: 0.9785 - val_auc: 0.6247 - val_accuracy: 0.5045\n",
      "Epoch 5/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1092 - auc: 0.9921 - accuracy: 0.9615\n",
      "Epoch 00005: val_accuracy did not improve from 0.52466\n",
      "243/243 [==============================] - 12s 49ms/step - loss: 0.1090 - auc: 0.9921 - accuracy: 0.9617 - val_loss: 1.0657 - val_auc: 0.6190 - val_accuracy: 0.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3642\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_123100-36ku1ktq/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_123100-36ku1ktq/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.1089765802025795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9921473264694214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9616971611976624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 1.0657312870025635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.6190049648284912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5022421479225159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 71\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601037137\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.7048797607421875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 181 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfancy-wood-61\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/36ku1ktq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_123217-7txmsi14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msweet-glitter-62\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/7txmsi14\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/7txmsi14</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.3143 - auc: 0.9634 - accuracy: 0.8933\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_62.h5\n",
      "243/243 [==============================] - 15s 63ms/step - loss: 0.3143 - auc: 0.9634 - accuracy: 0.8933 - val_loss: 0.7367 - val_auc: 0.5881 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1819 - auc: 0.9832 - accuracy: 0.9420\n",
      "Epoch 00002: val_accuracy improved from 0.50000 to 0.58072, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_62.h5\n",
      "243/243 [==============================] - 13s 55ms/step - loss: 0.1817 - auc: 0.9833 - accuracy: 0.9421 - val_loss: 0.6756 - val_auc: 0.6034 - val_accuracy: 0.5807\n",
      "Epoch 3/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1584 - auc: 0.9847 - accuracy: 0.9439\n",
      "Epoch 00003: val_accuracy did not improve from 0.58072\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1582 - auc: 0.9847 - accuracy: 0.9438 - val_loss: 0.7334 - val_auc: 0.6068 - val_accuracy: 0.5359\n",
      "Epoch 4/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1462 - auc: 0.9866 - accuracy: 0.9494\n",
      "Epoch 00004: val_accuracy did not improve from 0.58072\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1465 - auc: 0.9865 - accuracy: 0.9492 - val_loss: 0.6935 - val_auc: 0.6310 - val_accuracy: 0.5224\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1373 - auc: 0.9876 - accuracy: 0.9503\n",
      "Epoch 00005: val_accuracy improved from 0.58072 to 0.60314, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_62.h5\n",
      "243/243 [==============================] - 14s 58ms/step - loss: 0.1373 - auc: 0.9876 - accuracy: 0.9503 - val_loss: 0.6727 - val_auc: 0.6325 - val_accuracy: 0.6031\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1303 - auc: 0.9886 - accuracy: 0.9555\n",
      "Epoch 00006: val_accuracy improved from 0.60314 to 0.60762, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_62.h5\n",
      "243/243 [==============================] - 13s 55ms/step - loss: 0.1303 - auc: 0.9886 - accuracy: 0.9555 - val_loss: 0.6632 - val_auc: 0.6391 - val_accuracy: 0.6076\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1241 - auc: 0.9896 - accuracy: 0.9555\n",
      "Epoch 00007: val_accuracy improved from 0.60762 to 0.61659, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_62.h5\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1241 - auc: 0.9896 - accuracy: 0.9555 - val_loss: 0.6670 - val_auc: 0.6422 - val_accuracy: 0.6166\n",
      "Epoch 8/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1238 - auc: 0.9895 - accuracy: 0.9556\n",
      "Epoch 00008: val_accuracy did not improve from 0.61659\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1238 - auc: 0.9895 - accuracy: 0.9556 - val_loss: 0.9166 - val_auc: 0.6374 - val_accuracy: 0.5022\n",
      "Epoch 9/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1197 - auc: 0.9902 - accuracy: 0.9576\n",
      "Epoch 00009: val_accuracy did not improve from 0.61659\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1197 - auc: 0.9902 - accuracy: 0.9576 - val_loss: 0.7333 - val_auc: 0.6383 - val_accuracy: 0.5605\n",
      "Epoch 10/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1181 - auc: 0.9902 - accuracy: 0.9569\n",
      "Epoch 00010: val_accuracy did not improve from 0.61659\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1179 - auc: 0.9903 - accuracy: 0.9569 - val_loss: 0.8819 - val_auc: 0.6365 - val_accuracy: 0.5202\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1180 - auc: 0.9901 - accuracy: 0.9569\n",
      "Epoch 00011: val_accuracy did not improve from 0.61659\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1180 - auc: 0.9901 - accuracy: 0.9569 - val_loss: 1.1488 - val_auc: 0.6355 - val_accuracy: 0.4978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00011: early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_123217-7txmsi14/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_123217-7txmsi14/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.11796552687883377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9900861382484436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9569254517555237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 1.1488372087478638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.6355345845222473\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.49775785207748413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 151\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601037293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.6631854772567749\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 397 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msweet-glitter-62\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/7txmsi14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_123453-31pit1iy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcurious-grass-63\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/31pit1iy\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/31pit1iy</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.2131 - auc: 0.9750 - accuracy: 0.9236\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_63.h5\n",
      "243/243 [==============================] - 15s 64ms/step - loss: 0.2130 - auc: 0.9750 - accuracy: 0.9237 - val_loss: 1.0824 - val_auc: 0.5509 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1352 - auc: 0.9876 - accuracy: 0.9505\n",
      "Epoch 00002: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1352 - auc: 0.9876 - accuracy: 0.9505 - val_loss: 1.5655 - val_auc: 0.5796 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1214 - auc: 0.9897 - accuracy: 0.9555\n",
      "Epoch 00003: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1211 - auc: 0.9898 - accuracy: 0.9556 - val_loss: 1.9814 - val_auc: 0.5740 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1179 - auc: 0.9901 - accuracy: 0.9556\n",
      "Epoch 00004: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1175 - auc: 0.9901 - accuracy: 0.9558 - val_loss: 2.1701 - val_auc: 0.6029 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1166 - auc: 0.9899 - accuracy: 0.9605\n",
      "Epoch 00005: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1162 - auc: 0.9900 - accuracy: 0.9607 - val_loss: 2.1340 - val_auc: 0.6050 - val_accuracy: 0.5000\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 4504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_123453-31pit1iy/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_123453-31pit1iy/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.1162404790520668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9899508357048035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9606654644012451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 2.1340157985687256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.6050493717193604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 73\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601037374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 1.0823720693588257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 181 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mcurious-grass-63\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/31pit1iy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_123614-2r2jkgkl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstellar-sun-64\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/2r2jkgkl\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/2r2jkgkl</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.3247 - auc: 0.9587 - accuracy: 0.8815\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58744, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_64.h5\n",
      "243/243 [==============================] - 15s 64ms/step - loss: 0.3242 - auc: 0.9588 - accuracy: 0.8819 - val_loss: 0.6760 - val_auc: 0.6182 - val_accuracy: 0.5874\n",
      "Epoch 2/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1792 - auc: 0.9847 - accuracy: 0.9430\n",
      "Epoch 00002: val_accuracy improved from 0.58744 to 0.60538, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_64.h5\n",
      "243/243 [==============================] - 14s 56ms/step - loss: 0.1791 - auc: 0.9847 - accuracy: 0.9431 - val_loss: 0.6682 - val_auc: 0.6348 - val_accuracy: 0.6054\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1519 - auc: 0.9867 - accuracy: 0.9507\n",
      "Epoch 00003: val_accuracy did not improve from 0.60538\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1519 - auc: 0.9867 - accuracy: 0.9507 - val_loss: 0.6683 - val_auc: 0.6482 - val_accuracy: 0.6031\n",
      "Epoch 4/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1380 - auc: 0.9883 - accuracy: 0.9522\n",
      "Epoch 00004: val_accuracy did not improve from 0.60538\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1377 - auc: 0.9883 - accuracy: 0.9523 - val_loss: 0.7088 - val_auc: 0.6488 - val_accuracy: 0.5628\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1283 - auc: 0.9898 - accuracy: 0.9554\n",
      "Epoch 00005: val_accuracy did not improve from 0.60538\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1283 - auc: 0.9898 - accuracy: 0.9554 - val_loss: 0.7077 - val_auc: 0.6508 - val_accuracy: 0.5673\n",
      "Epoch 6/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1250 - auc: 0.9894 - accuracy: 0.9580\n",
      "Epoch 00006: val_accuracy did not improve from 0.60538\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1250 - auc: 0.9894 - accuracy: 0.9581 - val_loss: 0.7644 - val_auc: 0.6505 - val_accuracy: 0.5471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 4767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_123614-2r2jkgkl/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_123614-2r2jkgkl/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.1250438392162323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9894347786903381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9580861330032349\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 0.7643808126449585\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.6504654884338379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5470852255821228\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 88\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601037469\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.6682162880897522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 217 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mstellar-sun-64\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/2r2jkgkl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_123749-18ilz0s8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrestful-thunder-65\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/18ilz0s8\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/18ilz0s8</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.2625 - auc: 0.9686 - accuracy: 0.9093\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_65.h5\n",
      "243/243 [==============================] - 16s 67ms/step - loss: 0.2620 - auc: 0.9687 - accuracy: 0.9096 - val_loss: 0.8475 - val_auc: 0.6315 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1608 - auc: 0.9841 - accuracy: 0.9422\n",
      "Epoch 00002: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1608 - auc: 0.9841 - accuracy: 0.9422 - val_loss: 0.9383 - val_auc: 0.6394 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1412 - auc: 0.9869 - accuracy: 0.9506\n",
      "Epoch 00003: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.1412 - auc: 0.9869 - accuracy: 0.9506 - val_loss: 0.9253 - val_auc: 0.6398 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1354 - auc: 0.9870 - accuracy: 0.9530\n",
      "Epoch 00004: val_accuracy improved from 0.50000 to 0.57175, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_65.h5\n",
      "243/243 [==============================] - 14s 58ms/step - loss: 0.1355 - auc: 0.9870 - accuracy: 0.9529 - val_loss: 0.6775 - val_auc: 0.6525 - val_accuracy: 0.5717\n",
      "Epoch 5/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1293 - auc: 0.9880 - accuracy: 0.9547\n",
      "Epoch 00005: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1289 - auc: 0.9881 - accuracy: 0.9549 - val_loss: 0.7509 - val_auc: 0.6595 - val_accuracy: 0.5022\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1288 - auc: 0.9881 - accuracy: 0.9542\n",
      "Epoch 00006: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1288 - auc: 0.9881 - accuracy: 0.9542 - val_loss: 0.7158 - val_auc: 0.6592 - val_accuracy: 0.5112\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1211 - auc: 0.9895 - accuracy: 0.9551\n",
      "Epoch 00007: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1211 - auc: 0.9895 - accuracy: 0.9551 - val_loss: 0.6865 - val_auc: 0.6587 - val_accuracy: 0.5381\n",
      "Epoch 8/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1214 - auc: 0.9889 - accuracy: 0.9565\n",
      "Epoch 00008: val_accuracy improved from 0.57175 to 0.60762, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_65.h5\n",
      "243/243 [==============================] - 14s 56ms/step - loss: 0.1214 - auc: 0.9889 - accuracy: 0.9565 - val_loss: 0.6695 - val_auc: 0.6567 - val_accuracy: 0.6076\n",
      "Epoch 9/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1167 - auc: 0.9903 - accuracy: 0.9569\n",
      "Epoch 00009: val_accuracy did not improve from 0.60762\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1169 - auc: 0.9903 - accuracy: 0.9568 - val_loss: 0.7351 - val_auc: 0.6509 - val_accuracy: 0.5135\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1147 - auc: 0.9905 - accuracy: 0.9591\n",
      "Epoch 00010: val_accuracy did not improve from 0.60762\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1147 - auc: 0.9905 - accuracy: 0.9591 - val_loss: 0.7084 - val_auc: 0.6494 - val_accuracy: 0.5135\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1145 - auc: 0.9905 - accuracy: 0.9573\n",
      "Epoch 00011: val_accuracy did not improve from 0.60762\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1145 - auc: 0.9905 - accuracy: 0.9573 - val_loss: 0.7151 - val_auc: 0.6556 - val_accuracy: 0.5090\n",
      "Epoch 12/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1150 - auc: 0.9903 - accuracy: 0.9586\n",
      "Epoch 00012: val_accuracy did not improve from 0.60762\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1150 - auc: 0.9903 - accuracy: 0.9586 - val_loss: 0.7399 - val_auc: 0.6588 - val_accuracy: 0.5202\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 5078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_123749-18ilz0s8/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_123749-18ilz0s8/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.1150197759270668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9903134703636169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9586020112037659\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 0.7398959994316101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.6588308811187744\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5201793909072876\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601037640\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.6695404052734375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 433 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mrestful-thunder-65\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/18ilz0s8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_124040-1hpu585y\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mnoble-sound-66\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/1hpu585y\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/1hpu585y</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.4240 - auc: 0.9208 - accuracy: 0.8728\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_66.h5\n",
      "243/243 [==============================] - 16s 65ms/step - loss: 0.4228 - auc: 0.9211 - accuracy: 0.8731 - val_loss: 2.1236 - val_auc: 0.5558 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1978 - auc: 0.9752 - accuracy: 0.9222\n",
      "Epoch 00002: val_accuracy improved from 0.50000 to 0.55381, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_66.h5\n",
      "243/243 [==============================] - 14s 57ms/step - loss: 0.1973 - auc: 0.9753 - accuracy: 0.9224 - val_loss: 0.7084 - val_auc: 0.5798 - val_accuracy: 0.5538\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1731 - auc: 0.9807 - accuracy: 0.9360\n",
      "Epoch 00003: val_accuracy did not improve from 0.55381\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.1731 - auc: 0.9807 - accuracy: 0.9360 - val_loss: 1.4897 - val_auc: 0.5663 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.2310 - auc: 0.9717 - accuracy: 0.9247\n",
      "Epoch 00004: val_accuracy did not improve from 0.55381\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.2310 - auc: 0.9717 - accuracy: 0.9247 - val_loss: 1.8141 - val_auc: 0.5891 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.2039 - auc: 0.9776 - accuracy: 0.9362\n",
      "Epoch 00005: val_accuracy did not improve from 0.55381\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.2039 - auc: 0.9776 - accuracy: 0.9362 - val_loss: 1.2854 - val_auc: 0.5912 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.2007 - auc: 0.9776 - accuracy: 0.9360\n",
      "Epoch 00006: val_accuracy did not improve from 0.55381\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.2007 - auc: 0.9776 - accuracy: 0.9360 - val_loss: 2.9839 - val_auc: 0.5140 - val_accuracy: 0.5000\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 5662\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_124040-1hpu585y/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_124040-1hpu585y/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.20066426694393158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9775857329368591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9360330104827881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 2.9839208126068115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.5139656662940979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601037743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.7084090709686279\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 217 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mnoble-sound-66\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/1hpu585y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_124223-p8f0c6z0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcurious-frog-67\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/p8f0c6z0\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/p8f0c6z0</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.2679 - auc: 0.9655 - accuracy: 0.9245\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_67.h5\n",
      "243/243 [==============================] - 16s 66ms/step - loss: 0.2668 - auc: 0.9657 - accuracy: 0.9248 - val_loss: 2.0265 - val_auc: 0.4959 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1842 - auc: 0.9808 - accuracy: 0.9436\n",
      "Epoch 00002: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 14s 58ms/step - loss: 0.1842 - auc: 0.9808 - accuracy: 0.9436 - val_loss: 1.0347 - val_auc: 0.5237 - val_accuracy: 0.4865\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.2025 - auc: 0.9803 - accuracy: 0.9456\n",
      "Epoch 00003: val_accuracy improved from 0.50000 to 0.50224, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_67.h5\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.2025 - auc: 0.9803 - accuracy: 0.9456 - val_loss: 1.6481 - val_auc: 0.5112 - val_accuracy: 0.5022\n",
      "Epoch 4/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.2031 - auc: 0.9792 - accuracy: 0.9496\n",
      "Epoch 00004: val_accuracy did not improve from 0.50224\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.2024 - auc: 0.9793 - accuracy: 0.9497 - val_loss: 2.1803 - val_auc: 0.5058 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1368 - auc: 0.9875 - accuracy: 0.9615\n",
      "Epoch 00005: val_accuracy did not improve from 0.50224\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.1363 - auc: 0.9875 - accuracy: 0.9617 - val_loss: 2.1768 - val_auc: 0.5206 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.2126 - auc: 0.9807 - accuracy: 0.9497\n",
      "Epoch 00006: val_accuracy improved from 0.50224 to 0.54036, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_67.h5\n",
      "243/243 [==============================] - 14s 58ms/step - loss: 0.2126 - auc: 0.9807 - accuracy: 0.9497 - val_loss: 0.8314 - val_auc: 0.5844 - val_accuracy: 0.5404\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1422 - auc: 0.9873 - accuracy: 0.9644\n",
      "Epoch 00007: val_accuracy did not improve from 0.54036\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.1422 - auc: 0.9873 - accuracy: 0.9644 - val_loss: 2.4021 - val_auc: 0.5204 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1629 - auc: 0.9863 - accuracy: 0.9579\n",
      "Epoch 00008: val_accuracy did not improve from 0.54036\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.1623 - auc: 0.9863 - accuracy: 0.9581 - val_loss: 1.2163 - val_auc: 0.5318 - val_accuracy: 0.4955\n",
      "Epoch 9/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1590 - auc: 0.9861 - accuracy: 0.9609\n",
      "Epoch 00009: val_accuracy improved from 0.54036 to 0.54933, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_67.h5\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.1590 - auc: 0.9861 - accuracy: 0.9609 - val_loss: 0.8630 - val_auc: 0.5439 - val_accuracy: 0.5493\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1385 - auc: 0.9885 - accuracy: 0.9616\n",
      "Epoch 00010: val_accuracy did not improve from 0.54933\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.1385 - auc: 0.9885 - accuracy: 0.9616 - val_loss: 0.8587 - val_auc: 0.5325 - val_accuracy: 0.5426\n",
      "Epoch 11/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1192 - auc: 0.9910 - accuracy: 0.9659\n",
      "Epoch 00011: val_accuracy did not improve from 0.54933\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.1194 - auc: 0.9910 - accuracy: 0.9658 - val_loss: 1.8663 - val_auc: 0.5386 - val_accuracy: 0.5135\n",
      "Epoch 12/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1371 - auc: 0.9878 - accuracy: 0.9654\n",
      "Epoch 00012: val_accuracy improved from 0.54933 to 0.55381, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_67.h5\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.1371 - auc: 0.9878 - accuracy: 0.9654 - val_loss: 1.0956 - val_auc: 0.5582 - val_accuracy: 0.5538\n",
      "Epoch 13/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1410 - auc: 0.9886 - accuracy: 0.9624\n",
      "Epoch 00013: val_accuracy did not improve from 0.55381\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1415 - auc: 0.9885 - accuracy: 0.9625 - val_loss: 1.0927 - val_auc: 0.5440 - val_accuracy: 0.5359\n",
      "Epoch 14/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1159 - auc: 0.9903 - accuracy: 0.9699\n",
      "Epoch 00014: val_accuracy did not improve from 0.55381\n",
      "243/243 [==============================] - 13s 51ms/step - loss: 0.1159 - auc: 0.9903 - accuracy: 0.9699 - val_loss: 3.5240 - val_auc: 0.4812 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1542 - auc: 0.9869 - accuracy: 0.9608\n",
      "Epoch 00015: val_accuracy did not improve from 0.55381\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.1542 - auc: 0.9869 - accuracy: 0.9608 - val_loss: 2.6188 - val_auc: 0.5334 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1288 - auc: 0.9895 - accuracy: 0.9666\n",
      "Epoch 00016: val_accuracy did not improve from 0.55381\n",
      "243/243 [==============================] - 13s 51ms/step - loss: 0.1288 - auc: 0.9895 - accuracy: 0.9666 - val_loss: 3.2187 - val_auc: 0.5251 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 5998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00016: early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_124223-p8f0c6z0/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_124223-p8f0c6z0/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.1287740170955658\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9894830584526062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9665979146957397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 3.2186660766601562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.5251463055610657\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601037967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.8313824534416199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 577 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mcurious-frog-67\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/p8f0c6z0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_124607-3tltmdgr\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfine-vortex-68\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/3tltmdgr\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/3tltmdgr</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1588 - auc: 0.9824 - accuracy: 0.9381\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.52691, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_68.h5\n",
      "243/243 [==============================] - 16s 66ms/step - loss: 0.1582 - auc: 0.9825 - accuracy: 0.9384 - val_loss: 0.7616 - val_auc: 0.5608 - val_accuracy: 0.5269\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0980 - auc: 0.9928 - accuracy: 0.9639\n",
      "Epoch 00002: val_accuracy did not improve from 0.52691\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.0980 - auc: 0.9928 - accuracy: 0.9639 - val_loss: 0.9262 - val_auc: 0.5783 - val_accuracy: 0.5179\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0892 - auc: 0.9935 - accuracy: 0.9700\n",
      "Epoch 00003: val_accuracy improved from 0.52691 to 0.52915, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_68.h5\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.0892 - auc: 0.9935 - accuracy: 0.9700 - val_loss: 0.8989 - val_auc: 0.5965 - val_accuracy: 0.5291\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0787 - auc: 0.9951 - accuracy: 0.9721\n",
      "Epoch 00004: val_accuracy improved from 0.52915 to 0.59417, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_68.h5\n",
      "243/243 [==============================] - 14s 57ms/step - loss: 0.0787 - auc: 0.9951 - accuracy: 0.9721 - val_loss: 0.7251 - val_auc: 0.6087 - val_accuracy: 0.5942\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0711 - auc: 0.9960 - accuracy: 0.9729\n",
      "Epoch 00005: val_accuracy did not improve from 0.59417\n",
      "243/243 [==============================] - 14s 57ms/step - loss: 0.0711 - auc: 0.9960 - accuracy: 0.9729 - val_loss: 0.7209 - val_auc: 0.6181 - val_accuracy: 0.5897\n",
      "Epoch 6/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.0677 - auc: 0.9964 - accuracy: 0.9762\n",
      "Epoch 00006: val_accuracy improved from 0.59417 to 0.60538, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_68.h5\n",
      "243/243 [==============================] - 14s 57ms/step - loss: 0.0683 - auc: 0.9963 - accuracy: 0.9759 - val_loss: 0.6992 - val_auc: 0.6243 - val_accuracy: 0.6054\n",
      "Epoch 7/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.0667 - auc: 0.9960 - accuracy: 0.9759\n",
      "Epoch 00007: val_accuracy did not improve from 0.60538\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.0666 - auc: 0.9960 - accuracy: 0.9760 - val_loss: 0.7423 - val_auc: 0.6122 - val_accuracy: 0.5874\n",
      "Epoch 8/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.0617 - auc: 0.9963 - accuracy: 0.9785\n",
      "Epoch 00008: val_accuracy did not improve from 0.60538\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.0616 - auc: 0.9963 - accuracy: 0.9786 - val_loss: 0.7389 - val_auc: 0.6294 - val_accuracy: 0.5471\n",
      "Epoch 9/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.0572 - auc: 0.9969 - accuracy: 0.9801\n",
      "Epoch 00009: val_accuracy did not improve from 0.60538\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.0571 - auc: 0.9969 - accuracy: 0.9801 - val_loss: 0.7154 - val_auc: 0.6306 - val_accuracy: 0.5964\n",
      "Epoch 10/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.0540 - auc: 0.9973 - accuracy: 0.9816\n",
      "Epoch 00010: val_accuracy improved from 0.60538 to 0.60987, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_68.h5\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.0540 - auc: 0.9973 - accuracy: 0.9816 - val_loss: 0.7310 - val_auc: 0.6281 - val_accuracy: 0.6099\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0536 - auc: 0.9978 - accuracy: 0.9813\n",
      "Epoch 00011: val_accuracy did not improve from 0.60987\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.0536 - auc: 0.9978 - accuracy: 0.9813 - val_loss: 0.8979 - val_auc: 0.6077 - val_accuracy: 0.5695\n",
      "Epoch 12/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.0557 - auc: 0.9971 - accuracy: 0.9799\n",
      "Epoch 00012: val_accuracy did not improve from 0.60987\n",
      "243/243 [==============================] - 13s 53ms/step - loss: 0.0558 - auc: 0.9971 - accuracy: 0.9799 - val_loss: 0.7902 - val_auc: 0.6271 - val_accuracy: 0.6076\n",
      "Epoch 13/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0474 - auc: 0.9981 - accuracy: 0.9831\n",
      "Epoch 00013: val_accuracy improved from 0.60987 to 0.61883, saving model to /content/gdrive/ + My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/resnet50_68.h5\n",
      "243/243 [==============================] - 14s 56ms/step - loss: 0.0474 - auc: 0.9981 - accuracy: 0.9831 - val_loss: 0.7955 - val_auc: 0.6385 - val_accuracy: 0.6188\n",
      "Epoch 14/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0427 - auc: 0.9986 - accuracy: 0.9859\n",
      "Epoch 00014: val_accuracy did not improve from 0.61883\n",
      "243/243 [==============================] - 13s 54ms/step - loss: 0.0427 - auc: 0.9986 - accuracy: 0.9859 - val_loss: 0.9723 - val_auc: 0.6267 - val_accuracy: 0.5897\n",
      "Epoch 15/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0447 - auc: 0.9983 - accuracy: 0.9848\n",
      "Epoch 00015: val_accuracy did not improve from 0.61883\n",
      "243/243 [==============================] - 13s 55ms/step - loss: 0.0447 - auc: 0.9983 - accuracy: 0.9848 - val_loss: 0.7989 - val_auc: 0.6293 - val_accuracy: 0.6121\n",
      "Epoch 16/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0432 - auc: 0.9983 - accuracy: 0.9865\n",
      "Epoch 00016: val_accuracy did not improve from 0.61883\n",
      "243/243 [==============================] - 13s 54ms/step - loss: 0.0432 - auc: 0.9983 - accuracy: 0.9865 - val_loss: 1.1229 - val_auc: 0.6211 - val_accuracy: 0.5830\n",
      "Epoch 17/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.0415 - auc: 0.9985 - accuracy: 0.9868\n",
      "Epoch 00017: val_accuracy did not improve from 0.61883\n",
      "243/243 [==============================] - 13s 55ms/step - loss: 0.0415 - auc: 0.9985 - accuracy: 0.9868 - val_loss: 1.0077 - val_auc: 0.6177 - val_accuracy: 0.5897\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "for i, output_layer in enumerate(resnent50_last_layers):\n",
    "  print(f\"layer {i} - {output_layer} - out of {len(resnent50_last_layers)}\")\n",
    "  if output_layer.startswith(\"conv\"):\n",
    "    model_input['model_conf']['sota_model'] = \"ResNet50\"\n",
    "    model_input['model_conf']['sota_model_layer'] = output_layer\n",
    "\n",
    "    wandb_config()\n",
    "    model, mc, earlystop, final_model_path = build_model()\n",
    "    history_resnet50 = run_model(model, mc, earlystop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsXaHBQxLrYv"
   },
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P-iesBx4R2I"
   },
   "source": [
    "#### single layer approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7510,
     "status": "ok",
     "timestamp": 1601038816843,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "gRprXttLAavD",
    "outputId": "0705a7e7-00b0-443f-b241-6cae9a81c711"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33minbar_sh\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_130010-1pqr05d2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdevoted-galaxy-70\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/1pqr05d2\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/1pqr05d2</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: \"vgg19_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, None, None, 512)   15304768  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7168)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 7169      \n",
      "=================================================================\n",
      "Total params: 15,311,937\n",
      "Trainable params: 7,169\n",
      "Non-trainable params: 15,304,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_input['model_conf']['sota_model'] = \"VGG19\"\n",
    "model_input['model_conf']['sota_model_layer'] = \"block5_conv2\"\n",
    "\n",
    "# Creating and running the model\n",
    "wandb_config()\n",
    "model, mc, earlystop, final_model_path_vgg = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2r9f_apK4st"
   },
   "source": [
    "##### running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278026,
     "status": "ok",
     "timestamp": 1601033593299,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "dc02ZLwD7dyr",
    "outputId": "204eacbd-b739-4778-bbaf-d107d8b4bd7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 3.4307 - auc: 0.9427 - accuracy: 0.9461\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68161, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/vgg19_58.h5\n",
      "243/243 [==============================] - 26s 108ms/step - loss: 3.4307 - auc: 0.9427 - accuracy: 0.9461 - val_loss: 0.8691 - val_auc: 0.8658 - val_accuracy: 0.6816\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 2.0852 - auc: 0.9617 - accuracy: 0.9629\n",
      "Epoch 00002: val_accuracy improved from 0.68161 to 0.80269, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/vgg19_58.h5\n",
      "243/243 [==============================] - 23s 97ms/step - loss: 2.0852 - auc: 0.9617 - accuracy: 0.9629 - val_loss: 0.5122 - val_auc: 0.8819 - val_accuracy: 0.8027\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.9348 - auc: 0.9647 - accuracy: 0.9654\n",
      "Epoch 00003: val_accuracy did not improve from 0.80269\n",
      "243/243 [==============================] - 23s 93ms/step - loss: 1.9348 - auc: 0.9647 - accuracy: 0.9654 - val_loss: 1.0256 - val_auc: 0.8727 - val_accuracy: 0.7152\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.6586 - auc: 0.9698 - accuracy: 0.9725\n",
      "Epoch 00004: val_accuracy did not improve from 0.80269\n",
      "243/243 [==============================] - 22s 91ms/step - loss: 1.6586 - auc: 0.9698 - accuracy: 0.9725 - val_loss: 1.1808 - val_auc: 0.8638 - val_accuracy: 0.6749\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.4549 - auc: 0.9735 - accuracy: 0.9749\n",
      "Epoch 00005: val_accuracy did not improve from 0.80269\n",
      "243/243 [==============================] - 22s 92ms/step - loss: 1.4549 - auc: 0.9735 - accuracy: 0.9749 - val_loss: 0.8340 - val_auc: 0.8608 - val_accuracy: 0.7578\n",
      "Epoch 6/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 2.0489 - auc: 0.9702 - accuracy: 0.9715\n",
      "Epoch 00006: val_accuracy did not improve from 0.80269\n",
      "243/243 [==============================] - 22s 91ms/step - loss: 2.0489 - auc: 0.9702 - accuracy: 0.9715 - val_loss: 1.4222 - val_auc: 0.8572 - val_accuracy: 0.6996\n",
      "Epoch 7/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.6045 - auc: 0.9730 - accuracy: 0.9741\n",
      "Epoch 00007: val_accuracy did not improve from 0.80269\n",
      "243/243 [==============================] - 22s 92ms/step - loss: 1.6045 - auc: 0.9730 - accuracy: 0.9741 - val_loss: 0.6252 - val_auc: 0.8744 - val_accuracy: 0.7848\n",
      "Epoch 8/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.3892 - auc: 0.9758 - accuracy: 0.9769\n",
      "Epoch 00008: val_accuracy did not improve from 0.80269\n",
      "243/243 [==============================] - 22s 92ms/step - loss: 1.3892 - auc: 0.9758 - accuracy: 0.9769 - val_loss: 1.3033 - val_auc: 0.8541 - val_accuracy: 0.7018\n",
      "Epoch 9/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 2.1403 - auc: 0.9685 - accuracy: 0.9714\n",
      "Epoch 00009: val_accuracy did not improve from 0.80269\n",
      "243/243 [==============================] - 22s 92ms/step - loss: 2.1403 - auc: 0.9685 - accuracy: 0.9714 - val_loss: 1.1820 - val_auc: 0.8551 - val_accuracy: 0.7332\n",
      "Epoch 10/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.5900 - auc: 0.9773 - accuracy: 0.9787\n",
      "Epoch 00010: val_accuracy did not improve from 0.80269\n",
      "243/243 [==============================] - 22s 91ms/step - loss: 1.5900 - auc: 0.9773 - accuracy: 0.9787 - val_loss: 1.3160 - val_auc: 0.8517 - val_accuracy: 0.6861\n",
      "Epoch 11/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.9682 - auc: 0.9708 - accuracy: 0.9727\n",
      "Epoch 00011: val_accuracy did not improve from 0.80269\n",
      "243/243 [==============================] - 22s 91ms/step - loss: 1.9682 - auc: 0.9708 - accuracy: 0.9727 - val_loss: 1.1744 - val_auc: 0.8600 - val_accuracy: 0.7332\n",
      "Epoch 12/50\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.4761 - auc: 0.9798 - accuracy: 0.9814\n",
      "Epoch 00012: val_accuracy did not improve from 0.80269\n",
      "243/243 [==============================] - 22s 90ms/step - loss: 1.4761 - auc: 0.9798 - accuracy: 0.9814 - val_loss: 0.7443 - val_auc: 0.8599 - val_accuracy: 0.7713\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_vgg19 = run_model(model, mc, earlystop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VW3P8canULcJ"
   },
   "source": [
    "#### running a loop over several layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EVW2bkqUPTp"
   },
   "outputs": [],
   "source": [
    "# vgg19 = VGG19(include_top=False, weights=\"imagenet\", pooling='avg')\n",
    "# vgg19_last_layers = [layer.name for layer in vgg19.layers[-10:] if \"conv\" in layer.name]\n",
    "vgg19_last_layers = [\"block5_conv2\", \"block5_conv3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 924850,
     "status": "ok",
     "timestamp": 1601060083503,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "VUSHUbdkpdji",
    "outputId": "ab11312e-eb3b-461a-e123-c6f823628f7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkin model: VGG19\n",
      "layer 1 - block5_conv2 - out of 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33minbar_sh\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_184212-hroptend\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlikely-snowflake-106\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/hroptend\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/hroptend</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 3.4939 - auc: 0.8987 - accuracy: 0.8927\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64536, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg19_106.h5\n",
      "142/142 [==============================] - 28s 198ms/step - loss: 3.4939 - auc: 0.8987 - accuracy: 0.8927 - val_loss: 0.7001 - val_auc: 0.8551 - val_accuracy: 0.6454\n",
      "Epoch 2/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.7047 - auc: 0.9365 - accuracy: 0.9296\n",
      "Epoch 00002: val_accuracy did not improve from 0.64536\n",
      "142/142 [==============================] - 23s 159ms/step - loss: 1.7047 - auc: 0.9365 - accuracy: 0.9296 - val_loss: 0.9136 - val_auc: 0.8601 - val_accuracy: 0.5476\n",
      "Epoch 3/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.5421 - auc: 0.9401 - accuracy: 0.9342\n",
      "Epoch 00003: val_accuracy improved from 0.64536 to 0.77820, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg19_106.h5\n",
      "142/142 [==============================] - 24s 169ms/step - loss: 1.5421 - auc: 0.9401 - accuracy: 0.9342 - val_loss: 0.4616 - val_auc: 0.8697 - val_accuracy: 0.7782\n",
      "Epoch 4/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.1156 - auc: 0.9524 - accuracy: 0.9447\n",
      "Epoch 00004: val_accuracy did not improve from 0.77820\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 1.1156 - auc: 0.9524 - accuracy: 0.9447 - val_loss: 0.5119 - val_auc: 0.8574 - val_accuracy: 0.7469\n",
      "Epoch 5/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.3205 - auc: 0.9463 - accuracy: 0.9389\n",
      "Epoch 00005: val_accuracy did not improve from 0.77820\n",
      "142/142 [==============================] - 23s 162ms/step - loss: 1.3205 - auc: 0.9463 - accuracy: 0.9389 - val_loss: 0.6764 - val_auc: 0.8571 - val_accuracy: 0.6416\n",
      "Epoch 6/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.0142 - auc: 0.9547 - accuracy: 0.9465\n",
      "Epoch 00006: val_accuracy did not improve from 0.77820\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 1.0142 - auc: 0.9547 - accuracy: 0.9465 - val_loss: 0.7475 - val_auc: 0.8670 - val_accuracy: 0.6128\n",
      "Epoch 7/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.1580 - auc: 0.9534 - accuracy: 0.9470\n",
      "Epoch 00007: val_accuracy did not improve from 0.77820\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 1.1580 - auc: 0.9534 - accuracy: 0.9470 - val_loss: 0.5489 - val_auc: 0.8730 - val_accuracy: 0.7381\n",
      "Epoch 8/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.4845 - auc: 0.9479 - accuracy: 0.9434\n",
      "Epoch 00008: val_accuracy did not improve from 0.77820\n",
      "142/142 [==============================] - 23s 162ms/step - loss: 1.4845 - auc: 0.9479 - accuracy: 0.9434 - val_loss: 0.7787 - val_auc: 0.8800 - val_accuracy: 0.6115\n",
      "Epoch 9/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.8380 - auc: 0.9608 - accuracy: 0.9527\n",
      "Epoch 00009: val_accuracy did not improve from 0.77820\n",
      "142/142 [==============================] - 23s 162ms/step - loss: 0.8380 - auc: 0.9608 - accuracy: 0.9527 - val_loss: 0.6262 - val_auc: 0.8661 - val_accuracy: 0.6742\n",
      "Epoch 10/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.7469 - auc: 0.9637 - accuracy: 0.9562\n",
      "Epoch 00010: val_accuracy did not improve from 0.77820\n",
      "142/142 [==============================] - 23s 162ms/step - loss: 0.7469 - auc: 0.9637 - accuracy: 0.9562 - val_loss: 0.6048 - val_auc: 0.8686 - val_accuracy: 0.7030\n",
      "Epoch 11/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.2831 - auc: 0.9502 - accuracy: 0.9457\n",
      "Epoch 00011: val_accuracy did not improve from 0.77820\n",
      "142/142 [==============================] - 23s 161ms/step - loss: 1.2831 - auc: 0.9502 - accuracy: 0.9457 - val_loss: 0.8858 - val_auc: 0.8801 - val_accuracy: 0.5727\n",
      "Epoch 12/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.0235 - auc: 0.9574 - accuracy: 0.9512\n",
      "Epoch 00012: val_accuracy did not improve from 0.77820\n",
      "142/142 [==============================] - 23s 162ms/step - loss: 1.0235 - auc: 0.9574 - accuracy: 0.9512 - val_loss: 0.5067 - val_auc: 0.8645 - val_accuracy: 0.7619\n",
      "Epoch 13/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.9585 - auc: 0.9598 - accuracy: 0.9525\n",
      "Epoch 00013: val_accuracy did not improve from 0.77820\n",
      "142/142 [==============================] - 23s 162ms/step - loss: 0.9585 - auc: 0.9598 - accuracy: 0.9525 - val_loss: 0.5211 - val_auc: 0.8699 - val_accuracy: 0.7769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 36508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: early stopping\n",
      "layer 2 - block5_conv3 - out of 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_184212-hroptend/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_184212-hroptend/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.9585123062133789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9597605466842651\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9525442719459534\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 0.521108090877533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.8699254989624023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.7769423723220825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 321\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601059655\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.46162721514701843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 469 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlikely-snowflake-106\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/hroptend\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_184735-1ouweikn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtreasured-pine-107\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/1ouweikn\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/1ouweikn</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 3.0504 - auc: 0.8963 - accuracy: 0.8846\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69048, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg19_107.h5\n",
      "142/142 [==============================] - 25s 177ms/step - loss: 3.0504 - auc: 0.8963 - accuracy: 0.8846 - val_loss: 0.5996 - val_auc: 0.8274 - val_accuracy: 0.6905\n",
      "Epoch 2/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.6705 - auc: 0.9524 - accuracy: 0.9334\n",
      "Epoch 00002: val_accuracy improved from 0.69048 to 0.70927, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg19_107.h5\n",
      "142/142 [==============================] - 25s 179ms/step - loss: 0.6705 - auc: 0.9524 - accuracy: 0.9334 - val_loss: 0.5558 - val_auc: 0.8363 - val_accuracy: 0.7093\n",
      "Epoch 3/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.6320 - auc: 0.9549 - accuracy: 0.9338\n",
      "Epoch 00003: val_accuracy improved from 0.70927 to 0.75689, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg19_107.h5\n",
      "142/142 [==============================] - 25s 178ms/step - loss: 0.6320 - auc: 0.9549 - accuracy: 0.9338 - val_loss: 0.5169 - val_auc: 0.8621 - val_accuracy: 0.7569\n",
      "Epoch 4/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.4191 - auc: 0.9663 - accuracy: 0.9438\n",
      "Epoch 00004: val_accuracy did not improve from 0.75689\n",
      "142/142 [==============================] - 24s 168ms/step - loss: 0.4191 - auc: 0.9663 - accuracy: 0.9438 - val_loss: 0.5260 - val_auc: 0.8523 - val_accuracy: 0.7356\n",
      "Epoch 5/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.5327 - auc: 0.9600 - accuracy: 0.9408\n",
      "Epoch 00005: val_accuracy improved from 0.75689 to 0.77945, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg19_107.h5\n",
      "142/142 [==============================] - 26s 180ms/step - loss: 0.5327 - auc: 0.9600 - accuracy: 0.9408 - val_loss: 0.5095 - val_auc: 0.8645 - val_accuracy: 0.7794\n",
      "Epoch 6/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.5323 - auc: 0.9614 - accuracy: 0.9409\n",
      "Epoch 00006: val_accuracy did not improve from 0.77945\n",
      "142/142 [==============================] - 24s 170ms/step - loss: 0.5323 - auc: 0.9614 - accuracy: 0.9409 - val_loss: 0.5067 - val_auc: 0.8623 - val_accuracy: 0.7769\n",
      "Epoch 7/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.5162 - auc: 0.9635 - accuracy: 0.9425\n",
      "Epoch 00007: val_accuracy improved from 0.77945 to 0.78822, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg19_107.h5\n",
      "142/142 [==============================] - 25s 177ms/step - loss: 0.5162 - auc: 0.9635 - accuracy: 0.9425 - val_loss: 0.5007 - val_auc: 0.8703 - val_accuracy: 0.7882\n",
      "Epoch 8/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.3664 - auc: 0.9715 - accuracy: 0.9525\n",
      "Epoch 00008: val_accuracy did not improve from 0.78822\n",
      "142/142 [==============================] - 24s 167ms/step - loss: 0.3664 - auc: 0.9715 - accuracy: 0.9525 - val_loss: 0.5185 - val_auc: 0.8619 - val_accuracy: 0.7744\n",
      "Epoch 9/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.3768 - auc: 0.9700 - accuracy: 0.9514\n",
      "Epoch 00009: val_accuracy did not improve from 0.78822\n",
      "142/142 [==============================] - 24s 167ms/step - loss: 0.3768 - auc: 0.9700 - accuracy: 0.9514 - val_loss: 0.5191 - val_auc: 0.8467 - val_accuracy: 0.7632\n",
      "Epoch 10/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.3559 - auc: 0.9710 - accuracy: 0.9520\n",
      "Epoch 00010: val_accuracy did not improve from 0.78822\n",
      "142/142 [==============================] - 24s 168ms/step - loss: 0.3559 - auc: 0.9710 - accuracy: 0.9520 - val_loss: 0.5891 - val_auc: 0.8506 - val_accuracy: 0.7005\n",
      "Epoch 11/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.6199 - auc: 0.9589 - accuracy: 0.9399\n",
      "Epoch 00011: val_accuracy did not improve from 0.78822\n",
      "142/142 [==============================] - 24s 167ms/step - loss: 0.6199 - auc: 0.9589 - accuracy: 0.9399 - val_loss: 0.5082 - val_auc: 0.8713 - val_accuracy: 0.7769\n",
      "Epoch 12/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.4878 - auc: 0.9659 - accuracy: 0.9490\n",
      "Epoch 00012: val_accuracy did not improve from 0.78822\n",
      "142/142 [==============================] - 24s 170ms/step - loss: 0.4878 - auc: 0.9659 - accuracy: 0.9490 - val_loss: 0.4938 - val_auc: 0.8656 - val_accuracy: 0.7769\n",
      "Epoch 13/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.5085 - auc: 0.9653 - accuracy: 0.9466\n",
      "Epoch 00013: val_accuracy did not improve from 0.78822\n",
      "142/142 [==============================] - 24s 167ms/step - loss: 0.5085 - auc: 0.9653 - accuracy: 0.9466 - val_loss: 0.5311 - val_auc: 0.8608 - val_accuracy: 0.7632\n",
      "Epoch 14/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.3986 - auc: 0.9709 - accuracy: 0.9548\n",
      "Epoch 00014: val_accuracy did not improve from 0.78822\n",
      "142/142 [==============================] - 24s 167ms/step - loss: 0.3986 - auc: 0.9709 - accuracy: 0.9548 - val_loss: 0.5098 - val_auc: 0.8564 - val_accuracy: 0.7707\n",
      "Epoch 15/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.3825 - auc: 0.9713 - accuracy: 0.9563\n",
      "Epoch 00015: val_accuracy did not improve from 0.78822\n",
      "142/142 [==============================] - 24s 167ms/step - loss: 0.3825 - auc: 0.9713 - accuracy: 0.9563 - val_loss: 0.5063 - val_auc: 0.8573 - val_accuracy: 0.7757\n",
      "Epoch 16/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.4175 - auc: 0.9695 - accuracy: 0.9513\n",
      "Epoch 00016: val_accuracy did not improve from 0.78822\n",
      "142/142 [==============================] - 24s 167ms/step - loss: 0.4175 - auc: 0.9695 - accuracy: 0.9513 - val_loss: 0.5428 - val_auc: 0.8608 - val_accuracy: 0.7544\n",
      "Epoch 17/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.4664 - auc: 0.9669 - accuracy: 0.9509\n",
      "Epoch 00017: val_accuracy did not improve from 0.78822\n",
      "142/142 [==============================] - 24s 167ms/step - loss: 0.4664 - auc: 0.9669 - accuracy: 0.9509 - val_loss: 0.5678 - val_auc: 0.8609 - val_accuracy: 0.7268\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "run_several_layers(\"VGG19\", vgg19_last_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLFgK7luiZ_s"
   },
   "source": [
    "#### ploting chosen model of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kR_kJzGli-MS"
   },
   "outputs": [],
   "source": [
    "# change this\n",
    "models_to_plot = [\"vgg19_106.h5\", \"vgg19_107.h5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "executionInfo": {
     "elapsed": 2023,
     "status": "error",
     "timestamp": 1601060895900,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "Sco_lhneihln",
    "outputId": "b584259f-80dc-42d9-88a5-dfd8929e9a8c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-082f6021c3f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels_to_plot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mfinal_model_path_vgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_model_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mplot_roc_curve_of_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model_path_vgg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_model_path' is not defined"
     ]
    }
   ],
   "source": [
    "for model_path in models_to_plot: \n",
    "  final_model_path_vgg = final_model_path.replace(final_model_path.split(\"/\")[-1], model_path)\n",
    "  plot_roc_curve_of_models(final_model_path_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntxqLgvGj1hD"
   },
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEu6cK9WkEh7"
   },
   "outputs": [],
   "source": [
    "# vgg16 = VGG16(include_top=False, weights=\"imagenet\", pooling='avg')\n",
    "# vgg16_last_layers = [layer.name for layer in vgg16.layers[-10:] if \"conv\" in layer.name]\n",
    "# vgg16_last_layers\n",
    "\n",
    "vgg16_last_layers = [\"block5_conv2\", \"block4_conv3\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ojz-gt2omPuf"
   },
   "source": [
    "##### creating model for one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10410,
     "status": "ok",
     "timestamp": 1601042517343,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "23Ntp-N6j3cE",
    "outputId": "a530737e-928e-43da-e317-9d1c7f94bd46"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 13525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_134520-p27y83my/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_134520-p27y83my/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.09685280174016953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9930195212364197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9794944524765015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 0.9352400302886963\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.8585936427116394\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5067264437675476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601041815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.5378907322883606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 397 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msolar-shape-80\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/p27y83my\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_140147-2pn1y19r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meager-snowflake-81\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/2pn1y19r\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/2pn1y19r</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: \"vgg16_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, None, None, 512)   12354880  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7168)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 7169      \n",
      "=================================================================\n",
      "Total params: 12,362,049\n",
      "Trainable params: 7,169\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_input['model_conf']['sota_model'] = \"VGG16\"\n",
    "model_input['model_conf']['sota_model_layer'] = \"block5_conv2\"\n",
    "\n",
    "\n",
    "# Creating and running the model\n",
    "wandb_config()\n",
    "model, mc, earlystop, final_model_path_vgg = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asux4JnPmLPH"
   },
   "source": [
    "##### running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307243,
     "status": "ok",
     "timestamp": 1601042834690,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "7cX79yuckeb2",
    "outputId": "aa107af2-82e5-4344-abad-02bcf9393862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.8056 - auc: 0.9393 - accuracy: 0.9381\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78475, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg16_81.h5\n",
      "243/243 [==============================] - 21s 87ms/step - loss: 1.8056 - auc: 0.9393 - accuracy: 0.9381 - val_loss: 0.4774 - val_auc: 0.8781 - val_accuracy: 0.7848\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.9520 - auc: 0.9658 - accuracy: 0.9638\n",
      "Epoch 00002: val_accuracy did not improve from 0.78475\n",
      "243/243 [==============================] - 20s 82ms/step - loss: 0.9520 - auc: 0.9658 - accuracy: 0.9638 - val_loss: 0.7845 - val_auc: 0.8782 - val_accuracy: 0.6502\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.4360 - auc: 0.9619 - accuracy: 0.9626\n",
      "Epoch 00003: val_accuracy did not improve from 0.78475\n",
      "243/243 [==============================] - 20s 84ms/step - loss: 1.4360 - auc: 0.9619 - accuracy: 0.9626 - val_loss: 0.8560 - val_auc: 0.8798 - val_accuracy: 0.6726\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.8753 - auc: 0.9711 - accuracy: 0.9709\n",
      "Epoch 00004: val_accuracy improved from 0.78475 to 0.79821, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg16_81.h5\n",
      "243/243 [==============================] - 22s 89ms/step - loss: 0.8753 - auc: 0.9711 - accuracy: 0.9709 - val_loss: 0.4633 - val_auc: 0.8746 - val_accuracy: 0.7982\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.8841 - auc: 0.9736 - accuracy: 0.9716\n",
      "Epoch 00005: val_accuracy improved from 0.79821 to 0.81614, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg16_81.h5\n",
      "243/243 [==============================] - 20s 83ms/step - loss: 0.8841 - auc: 0.9736 - accuracy: 0.9716 - val_loss: 0.4640 - val_auc: 0.8814 - val_accuracy: 0.8161\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.8197 - auc: 0.9723 - accuracy: 0.9732\n",
      "Epoch 00006: val_accuracy did not improve from 0.81614\n",
      "243/243 [==============================] - 19s 78ms/step - loss: 0.8197 - auc: 0.9723 - accuracy: 0.9732 - val_loss: 0.4907 - val_auc: 0.8683 - val_accuracy: 0.7915\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.6598 - auc: 0.9781 - accuracy: 0.9774\n",
      "Epoch 00007: val_accuracy did not improve from 0.81614\n",
      "243/243 [==============================] - 21s 87ms/step - loss: 0.6598 - auc: 0.9781 - accuracy: 0.9774 - val_loss: 0.4735 - val_auc: 0.8732 - val_accuracy: 0.8072\n",
      "Epoch 8/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.4777 - auc: 0.9626 - accuracy: 0.9636\n",
      "Epoch 00008: val_accuracy did not improve from 0.81614\n",
      "243/243 [==============================] - 20s 82ms/step - loss: 1.4777 - auc: 0.9626 - accuracy: 0.9636 - val_loss: 0.4949 - val_auc: 0.8849 - val_accuracy: 0.8117\n",
      "Epoch 9/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.9631 - auc: 0.9746 - accuracy: 0.9746\n",
      "Epoch 00009: val_accuracy did not improve from 0.81614\n",
      "243/243 [==============================] - 20s 84ms/step - loss: 0.9631 - auc: 0.9746 - accuracy: 0.9746 - val_loss: 1.1828 - val_auc: 0.8742 - val_accuracy: 0.6480\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.7623 - auc: 0.9791 - accuracy: 0.9788\n",
      "Epoch 00010: val_accuracy did not improve from 0.81614\n",
      "243/243 [==============================] - 20s 82ms/step - loss: 0.7623 - auc: 0.9791 - accuracy: 0.9788 - val_loss: 0.6989 - val_auc: 0.8716 - val_accuracy: 0.7735\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.9209 - auc: 0.9760 - accuracy: 0.9763\n",
      "Epoch 00011: val_accuracy did not improve from 0.81614\n",
      "243/243 [==============================] - 20s 82ms/step - loss: 0.9209 - auc: 0.9760 - accuracy: 0.9763 - val_loss: 0.6965 - val_auc: 0.8727 - val_accuracy: 0.7556\n",
      "Epoch 12/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.6622 - auc: 0.9796 - accuracy: 0.9786\n",
      "Epoch 00012: val_accuracy did not improve from 0.81614\n",
      "243/243 [==============================] - 19s 77ms/step - loss: 0.6622 - auc: 0.9796 - accuracy: 0.9786 - val_loss: 0.6087 - val_auc: 0.8582 - val_accuracy: 0.7623\n",
      "Epoch 13/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.0395 - auc: 0.9725 - accuracy: 0.9721\n",
      "Epoch 00013: val_accuracy did not improve from 0.81614\n",
      "243/243 [==============================] - 19s 80ms/step - loss: 1.0395 - auc: 0.9725 - accuracy: 0.9721 - val_loss: 0.6600 - val_auc: 0.8750 - val_accuracy: 0.7848\n",
      "Epoch 14/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.8243 - auc: 0.9768 - accuracy: 0.9776\n",
      "Epoch 00014: val_accuracy did not improve from 0.81614\n",
      "243/243 [==============================] - 20s 84ms/step - loss: 0.8243 - auc: 0.9768 - accuracy: 0.9776 - val_loss: 0.7472 - val_auc: 0.8731 - val_accuracy: 0.7578\n",
      "Epoch 15/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.9386 - auc: 0.9766 - accuracy: 0.9768\n",
      "Epoch 00015: val_accuracy did not improve from 0.81614\n",
      "243/243 [==============================] - 20s 84ms/step - loss: 0.9386 - auc: 0.9766 - accuracy: 0.9768 - val_loss: 0.6321 - val_auc: 0.8717 - val_accuracy: 0.7803\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_vgg16 = run_model(model, mc, earlystop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_CRNx4XmCl0"
   },
   "source": [
    "\n",
    "#### running a loop over several layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 808574,
     "status": "ok",
     "timestamp": 1601060892126,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "rQXbc7T9pryk",
    "outputId": "b2d2d232-a43d-4933-9668-93aa8ae6c482"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 37209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkin model: VGG16\n",
      "layer 1 - block5_conv2 - out of 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_184735-1ouweikn/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_184735-1ouweikn/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.4663920998573303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9668552279472351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9508849382400513\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 0.5677517652511597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.8608959317207336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.7268170714378357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 420\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601060082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.4938254952430725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 613 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mtreasured-pine-107\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/1ouweikn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_185444-1rslfvbz\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meager-sunset-108\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/1rslfvbz\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/1rslfvbz</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 2.0658 - auc: 0.9082 - accuracy: 0.8935\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68045, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg16_108.h5\n",
      "142/142 [==============================] - 20s 141ms/step - loss: 2.0658 - auc: 0.9082 - accuracy: 0.8935 - val_loss: 0.5783 - val_auc: 0.8399 - val_accuracy: 0.6805\n",
      "Epoch 2/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.7391 - auc: 0.9485 - accuracy: 0.9277\n",
      "Epoch 00002: val_accuracy improved from 0.68045 to 0.77193, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg16_108.h5\n",
      "142/142 [==============================] - 20s 144ms/step - loss: 0.7391 - auc: 0.9485 - accuracy: 0.9277 - val_loss: 0.5104 - val_auc: 0.8544 - val_accuracy: 0.7719\n",
      "Epoch 3/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.6397 - auc: 0.9574 - accuracy: 0.9400\n",
      "Epoch 00003: val_accuracy did not improve from 0.77193\n",
      "142/142 [==============================] - 19s 136ms/step - loss: 0.6397 - auc: 0.9574 - accuracy: 0.9400 - val_loss: 0.5334 - val_auc: 0.8429 - val_accuracy: 0.7481\n",
      "Epoch 4/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.7762 - auc: 0.9498 - accuracy: 0.9334\n",
      "Epoch 00004: val_accuracy did not improve from 0.77193\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 0.7762 - auc: 0.9498 - accuracy: 0.9334 - val_loss: 0.7686 - val_auc: 0.8677 - val_accuracy: 0.5514\n",
      "Epoch 5/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.6992 - auc: 0.9561 - accuracy: 0.9420\n",
      "Epoch 00005: val_accuracy did not improve from 0.77193\n",
      "142/142 [==============================] - 19s 137ms/step - loss: 0.6992 - auc: 0.9561 - accuracy: 0.9420 - val_loss: 0.5682 - val_auc: 0.8744 - val_accuracy: 0.6717\n",
      "Epoch 6/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.5199 - auc: 0.9640 - accuracy: 0.9442\n",
      "Epoch 00006: val_accuracy did not improve from 0.77193\n",
      "142/142 [==============================] - 19s 136ms/step - loss: 0.5199 - auc: 0.9640 - accuracy: 0.9442 - val_loss: 0.5405 - val_auc: 0.8641 - val_accuracy: 0.7306\n",
      "Epoch 7/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.5969 - auc: 0.9610 - accuracy: 0.9448\n",
      "Epoch 00007: val_accuracy did not improve from 0.77193\n",
      "142/142 [==============================] - 19s 136ms/step - loss: 0.5969 - auc: 0.9610 - accuracy: 0.9448 - val_loss: 0.5363 - val_auc: 0.8639 - val_accuracy: 0.7193\n",
      "Epoch 8/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.5472 - auc: 0.9612 - accuracy: 0.9463\n",
      "Epoch 00008: val_accuracy improved from 0.77193 to 0.80075, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg16_108.h5\n",
      "142/142 [==============================] - 21s 147ms/step - loss: 0.5472 - auc: 0.9612 - accuracy: 0.9463 - val_loss: 0.4883 - val_auc: 0.8722 - val_accuracy: 0.8008\n",
      "Epoch 9/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.5660 - auc: 0.9619 - accuracy: 0.9471\n",
      "Epoch 00009: val_accuracy did not improve from 0.80075\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 0.5660 - auc: 0.9619 - accuracy: 0.9471 - val_loss: 0.5509 - val_auc: 0.8578 - val_accuracy: 0.7206\n",
      "Epoch 10/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.6046 - auc: 0.9606 - accuracy: 0.9444\n",
      "Epoch 00010: val_accuracy did not improve from 0.80075\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 0.6046 - auc: 0.9606 - accuracy: 0.9444 - val_loss: 0.8126 - val_auc: 0.8742 - val_accuracy: 0.5539\n",
      "Epoch 11/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.6972 - auc: 0.9586 - accuracy: 0.9471\n",
      "Epoch 00011: val_accuracy did not improve from 0.80075\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 0.6972 - auc: 0.9586 - accuracy: 0.9471 - val_loss: 0.5208 - val_auc: 0.8562 - val_accuracy: 0.7544\n",
      "Epoch 12/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.4942 - auc: 0.9654 - accuracy: 0.9488\n",
      "Epoch 00012: val_accuracy did not improve from 0.80075\n",
      "142/142 [==============================] - 19s 136ms/step - loss: 0.4942 - auc: 0.9654 - accuracy: 0.9488 - val_loss: 0.5262 - val_auc: 0.8635 - val_accuracy: 0.7556\n",
      "Epoch 13/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.3743 - auc: 0.9722 - accuracy: 0.9554\n",
      "Epoch 00013: val_accuracy did not improve from 0.80075\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 0.3743 - auc: 0.9722 - accuracy: 0.9554 - val_loss: 0.5610 - val_auc: 0.8698 - val_accuracy: 0.7118\n",
      "Epoch 14/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.4930 - auc: 0.9668 - accuracy: 0.9467\n",
      "Epoch 00014: val_accuracy did not improve from 0.80075\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 0.4930 - auc: 0.9668 - accuracy: 0.9467 - val_loss: 0.5551 - val_auc: 0.8754 - val_accuracy: 0.7168\n",
      "Epoch 15/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.5801 - auc: 0.9621 - accuracy: 0.9496\n",
      "Epoch 00015: val_accuracy did not improve from 0.80075\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 0.5801 - auc: 0.9621 - accuracy: 0.9496 - val_loss: 0.5691 - val_auc: 0.8758 - val_accuracy: 0.7005\n",
      "Epoch 16/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.4034 - auc: 0.9702 - accuracy: 0.9548\n",
      "Epoch 00016: val_accuracy did not improve from 0.80075\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 0.4034 - auc: 0.9702 - accuracy: 0.9548 - val_loss: 0.5735 - val_auc: 0.8712 - val_accuracy: 0.6729\n",
      "Epoch 17/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.5222 - auc: 0.9659 - accuracy: 0.9478\n",
      "Epoch 00017: val_accuracy did not improve from 0.80075\n",
      "142/142 [==============================] - 19s 136ms/step - loss: 0.5222 - auc: 0.9659 - accuracy: 0.9478 - val_loss: 0.5682 - val_auc: 0.8676 - val_accuracy: 0.7018\n",
      "Epoch 18/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.3790 - auc: 0.9722 - accuracy: 0.9562\n",
      "Epoch 00018: val_accuracy did not improve from 0.80075\n",
      "142/142 [==============================] - 19s 135ms/step - loss: 0.3790 - auc: 0.9722 - accuracy: 0.9562 - val_loss: 0.5310 - val_auc: 0.8667 - val_accuracy: 0.7594\n",
      "Epoch 00018: early stopping"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 38142\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layer 2 - block4_conv3 - out of 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_185444-1rslfvbz/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_185444-1rslfvbz/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.37902840971946716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9721662402153015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9561946988105774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 0.5309565663337708\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.8666843771934509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.7593985199928284\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 358\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601060449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.4883078634738922\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 649 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33meager-sunset-108\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/1rslfvbz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_190049-16zizziu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdandy-serenity-109\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/16zizziu\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/16zizziu</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 6.7174 - auc: 0.9221 - accuracy: 0.9217\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.54637, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg16_109.h5\n",
      "142/142 [==============================] - 19s 134ms/step - loss: 6.7174 - auc: 0.9221 - accuracy: 0.9217 - val_loss: 2.2251 - val_auc: 0.7887 - val_accuracy: 0.5464\n",
      "Epoch 2/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 3.5871 - auc: 0.9430 - accuracy: 0.9420\n",
      "Epoch 00002: val_accuracy improved from 0.54637 to 0.70175, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg16_109.h5\n",
      "142/142 [==============================] - 20s 138ms/step - loss: 3.5871 - auc: 0.9430 - accuracy: 0.9420 - val_loss: 1.0079 - val_auc: 0.8560 - val_accuracy: 0.7018\n",
      "Epoch 3/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 4.2130 - auc: 0.9430 - accuracy: 0.9434\n",
      "Epoch 00003: val_accuracy improved from 0.70175 to 0.74561, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg16_109.h5\n",
      "142/142 [==============================] - 19s 133ms/step - loss: 4.2130 - auc: 0.9430 - accuracy: 0.9434 - val_loss: 1.0431 - val_auc: 0.8593 - val_accuracy: 0.7456\n",
      "Epoch 4/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 2.9136 - auc: 0.9535 - accuracy: 0.9530\n",
      "Epoch 00004: val_accuracy did not improve from 0.74561\n",
      "142/142 [==============================] - 18s 130ms/step - loss: 2.9136 - auc: 0.9535 - accuracy: 0.9530 - val_loss: 1.1544 - val_auc: 0.8537 - val_accuracy: 0.7155\n",
      "Epoch 5/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 4.1919 - auc: 0.9469 - accuracy: 0.9473\n",
      "Epoch 00005: val_accuracy did not improve from 0.74561\n",
      "142/142 [==============================] - 18s 129ms/step - loss: 4.1919 - auc: 0.9469 - accuracy: 0.9473 - val_loss: 3.3950 - val_auc: 0.7139 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 3.4882 - auc: 0.9582 - accuracy: 0.9581\n",
      "Epoch 00006: val_accuracy did not improve from 0.74561\n",
      "142/142 [==============================] - 18s 128ms/step - loss: 3.4882 - auc: 0.9582 - accuracy: 0.9581 - val_loss: 2.0341 - val_auc: 0.7961 - val_accuracy: 0.6341\n",
      "Epoch 7/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 3.2525 - auc: 0.9566 - accuracy: 0.9576\n",
      "Epoch 00007: val_accuracy improved from 0.74561 to 0.75313, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg16_109.h5\n",
      "142/142 [==============================] - 19s 134ms/step - loss: 3.2525 - auc: 0.9566 - accuracy: 0.9576 - val_loss: 1.0995 - val_auc: 0.8563 - val_accuracy: 0.7531\n",
      "Epoch 8/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 2.2602 - auc: 0.9639 - accuracy: 0.9644\n",
      "Epoch 00008: val_accuracy did not improve from 0.75313\n",
      "142/142 [==============================] - 18s 128ms/step - loss: 2.2602 - auc: 0.9639 - accuracy: 0.9644 - val_loss: 1.5715 - val_auc: 0.8263 - val_accuracy: 0.6930\n",
      "Epoch 9/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 2.7294 - auc: 0.9629 - accuracy: 0.9634\n",
      "Epoch 00009: val_accuracy did not improve from 0.75313\n",
      "142/142 [==============================] - 18s 129ms/step - loss: 2.7294 - auc: 0.9629 - accuracy: 0.9634 - val_loss: 2.0040 - val_auc: 0.8121 - val_accuracy: 0.6654\n",
      "Epoch 10/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 3.0449 - auc: 0.9595 - accuracy: 0.9593\n",
      "Epoch 00010: val_accuracy did not improve from 0.75313\n",
      "142/142 [==============================] - 18s 129ms/step - loss: 3.0449 - auc: 0.9595 - accuracy: 0.9593 - val_loss: 1.3184 - val_auc: 0.8418 - val_accuracy: 0.7456\n",
      "Epoch 11/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 2.5157 - auc: 0.9664 - accuracy: 0.9666\n",
      "Epoch 00011: val_accuracy improved from 0.75313 to 0.78070, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg16_109.h5\n",
      "142/142 [==============================] - 19s 134ms/step - loss: 2.5157 - auc: 0.9664 - accuracy: 0.9666 - val_loss: 0.9525 - val_auc: 0.8664 - val_accuracy: 0.7807\n",
      "Epoch 12/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 3.4882 - auc: 0.9621 - accuracy: 0.9617\n",
      "Epoch 00012: val_accuracy did not improve from 0.78070\n",
      "142/142 [==============================] - 18s 128ms/step - loss: 3.4882 - auc: 0.9621 - accuracy: 0.9617 - val_loss: 3.5525 - val_auc: 0.7247 - val_accuracy: 0.6028\n",
      "Epoch 13/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 3.4488 - auc: 0.9599 - accuracy: 0.9617\n",
      "Epoch 00013: val_accuracy improved from 0.78070 to 0.79699, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/vgg16_109.h5\n",
      "142/142 [==============================] - 19s 132ms/step - loss: 3.4488 - auc: 0.9599 - accuracy: 0.9617 - val_loss: 1.2007 - val_auc: 0.8606 - val_accuracy: 0.7970\n",
      "Epoch 14/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 2.6880 - auc: 0.9681 - accuracy: 0.9681\n",
      "Epoch 00014: val_accuracy did not improve from 0.79699\n",
      "142/142 [==============================] - 18s 128ms/step - loss: 2.6880 - auc: 0.9681 - accuracy: 0.9681 - val_loss: 1.0571 - val_auc: 0.8591 - val_accuracy: 0.7932\n",
      "Epoch 15/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.8107 - auc: 0.9719 - accuracy: 0.9719\n",
      "Epoch 00015: val_accuracy did not improve from 0.79699\n",
      "142/142 [==============================] - 18s 128ms/step - loss: 1.8107 - auc: 0.9719 - accuracy: 0.9719 - val_loss: 1.2990 - val_auc: 0.8511 - val_accuracy: 0.7594\n",
      "Epoch 16/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 2.8192 - auc: 0.9663 - accuracy: 0.9664\n",
      "Epoch 00016: val_accuracy did not improve from 0.79699\n",
      "142/142 [==============================] - 18s 128ms/step - loss: 2.8192 - auc: 0.9663 - accuracy: 0.9664 - val_loss: 1.1428 - val_auc: 0.8569 - val_accuracy: 0.7820\n",
      "Epoch 17/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.8342 - auc: 0.9731 - accuracy: 0.9723\n",
      "Epoch 00017: val_accuracy did not improve from 0.79699\n",
      "142/142 [==============================] - 18s 128ms/step - loss: 1.8342 - auc: 0.9731 - accuracy: 0.9723 - val_loss: 1.6944 - val_auc: 0.8318 - val_accuracy: 0.7243\n",
      "Epoch 18/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 2.3115 - auc: 0.9693 - accuracy: 0.9694\n",
      "Epoch 00018: val_accuracy did not improve from 0.79699\n",
      "142/142 [==============================] - 18s 127ms/step - loss: 2.3115 - auc: 0.9693 - accuracy: 0.9694 - val_loss: 1.1991 - val_auc: 0.8617 - val_accuracy: 0.7895\n",
      "Epoch 19/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 2.1336 - auc: 0.9717 - accuracy: 0.9718\n",
      "Epoch 00019: val_accuracy did not improve from 0.79699\n",
      "142/142 [==============================] - 18s 128ms/step - loss: 2.1336 - auc: 0.9717 - accuracy: 0.9718 - val_loss: 1.8163 - val_auc: 0.8196 - val_accuracy: 0.7256\n",
      "Epoch 20/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 2.9027 - auc: 0.9672 - accuracy: 0.9681\n",
      "Epoch 00020: val_accuracy did not improve from 0.79699\n",
      "142/142 [==============================] - 18s 128ms/step - loss: 2.9027 - auc: 0.9672 - accuracy: 0.9681 - val_loss: 1.7978 - val_auc: 0.8244 - val_accuracy: 0.7193\n",
      "Epoch 21/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.6600 - auc: 0.9778 - accuracy: 0.9778\n",
      "Epoch 00021: val_accuracy did not improve from 0.79699\n",
      "142/142 [==============================] - 18s 128ms/step - loss: 1.6600 - auc: 0.9778 - accuracy: 0.9778 - val_loss: 2.2250 - val_auc: 0.7997 - val_accuracy: 0.6855\n",
      "Epoch 22/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 2.3233 - auc: 0.9711 - accuracy: 0.9718\n",
      "Epoch 00022: val_accuracy did not improve from 0.79699\n",
      "142/142 [==============================] - 18s 128ms/step - loss: 2.3233 - auc: 0.9711 - accuracy: 0.9718 - val_loss: 1.5833 - val_auc: 0.8329 - val_accuracy: 0.7381\n",
      "Epoch 23/100\n",
      "142/142 [==============================] - ETA: 0s - loss: 1.9839 - auc: 0.9749 - accuracy: 0.9742\n",
      "Epoch 00023: val_accuracy did not improve from 0.79699\n",
      "142/142 [==============================] - 18s 128ms/step - loss: 1.9839 - auc: 0.9749 - accuracy: 0.9742 - val_loss: 1.2228 - val_auc: 0.8543 - val_accuracy: 0.7769\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "run_several_layers(\"VGG16\", vgg16_last_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8tD-PLntwsY"
   },
   "source": [
    "#### ploting chosen models of vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pnNppsDtsTo"
   },
   "outputs": [],
   "source": [
    "# update this\n",
    "models_to_plot = [\"vgg16_108.h5\", \"vgg16_109.h5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvYDctuat9ew"
   },
   "outputs": [],
   "source": [
    "for model_path in models_to_plot: \n",
    "  final_model_path_vgg = final_model_path.replace(final_model_path.split(\"/\")[-1], model_path)\n",
    "  plot_roc_curve_of_models(final_model_path_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAJR55BHmqnH"
   },
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3828,
     "status": "ok",
     "timestamp": 1601045556186,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "23nj2EJqmw3n",
    "outputId": "a79ef1f8-4a73-466f-cd93-e9fb542cd94f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['block14_sepconv1',\n",
       " 'block14_sepconv1_bn',\n",
       " 'block14_sepconv1_act',\n",
       " 'block14_sepconv2',\n",
       " 'block14_sepconv2_bn',\n",
       " 'block14_sepconv2_act']"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xception = Xception(include_top=False, weights=\"imagenet\", pooling='avg')\n",
    "xception_last_layers = [layer.name for layer in xception.layers[-10:] if \"conv\" in layer.name]\n",
    "xception_last_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOda6G_GnAIY"
   },
   "outputs": [],
   "source": [
    "#xception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1421000,
     "status": "ok",
     "timestamp": 1601047093355,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "YFXqZqfGnDb8",
    "outputId": "2a3f286d-07df-4373-ad58-f29e3f076120"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 19678\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkin model: Xception\n",
      "layer 0 - block14_sepconv1 - out of 6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_143715-34n3726n/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_143715-34n3726n/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.10133065283298492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9921832084655762\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9771730899810791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 0.5309321284294128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.8140320777893066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.7376681566238403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601044879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.5088328123092651\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 397 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myouthful-wind-87\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/34n3726n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_145432-34sije2y\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpretty-bush-88\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/34sije2y\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/34sije2y</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 2.3554 - auc: 0.8706 - accuracy: 0.8572\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_88.h5\n",
      "243/243 [==============================] - 17s 71ms/step - loss: 2.3554 - auc: 0.8706 - accuracy: 0.8572 - val_loss: 1.0280 - val_auc: 0.5788 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.6885 - auc: 0.9427 - accuracy: 0.9149\n",
      "Epoch 00002: val_accuracy improved from 0.50000 to 0.53587, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_88.h5\n",
      "243/243 [==============================] - 15s 61ms/step - loss: 0.6918 - auc: 0.9426 - accuracy: 0.9146 - val_loss: 0.7154 - val_auc: 0.6178 - val_accuracy: 0.5359\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.9092 - auc: 0.9272 - accuracy: 0.9083\n",
      "Epoch 00003: val_accuracy did not improve from 0.53587\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.9092 - auc: 0.9272 - accuracy: 0.9083 - val_loss: 0.7821 - val_auc: 0.6073 - val_accuracy: 0.5179\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.0220 - auc: 0.9326 - accuracy: 0.9200\n",
      "Epoch 00004: val_accuracy did not improve from 0.53587\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 1.0220 - auc: 0.9326 - accuracy: 0.9200 - val_loss: 0.9228 - val_auc: 0.6060 - val_accuracy: 0.5022\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.8486 - auc: 0.9430 - accuracy: 0.9287\n",
      "Epoch 00005: val_accuracy improved from 0.53587 to 0.56278, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_88.h5\n",
      "243/243 [==============================] - 15s 60ms/step - loss: 0.8486 - auc: 0.9430 - accuracy: 0.9287 - val_loss: 0.7037 - val_auc: 0.5984 - val_accuracy: 0.5628\n",
      "Epoch 6/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 1.1947 - auc: 0.9330 - accuracy: 0.9210\n",
      "Epoch 00006: val_accuracy did not improve from 0.56278\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 1.1923 - auc: 0.9332 - accuracy: 0.9212 - val_loss: 1.5241 - val_auc: 0.5773 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.6963 - auc: 0.9092 - accuracy: 0.9029\n",
      "Epoch 00007: val_accuracy improved from 0.56278 to 0.58072, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_88.h5\n",
      "243/243 [==============================] - 14s 56ms/step - loss: 1.6963 - auc: 0.9092 - accuracy: 0.9029 - val_loss: 0.7310 - val_auc: 0.5964 - val_accuracy: 0.5807\n",
      "Epoch 8/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.2400 - auc: 0.9395 - accuracy: 0.9306\n",
      "Epoch 00008: val_accuracy did not improve from 0.58072\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 1.2400 - auc: 0.9395 - accuracy: 0.9306 - val_loss: 0.8427 - val_auc: 0.5832 - val_accuracy: 0.5538\n",
      "Epoch 9/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 1.2951 - auc: 0.9300 - accuracy: 0.9217\n",
      "Epoch 00009: val_accuracy did not improve from 0.58072\n",
      "243/243 [==============================] - 12s 49ms/step - loss: 1.2948 - auc: 0.9302 - accuracy: 0.9218 - val_loss: 1.6448 - val_auc: 0.5702 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.8616 - auc: 0.9474 - accuracy: 0.9380\n",
      "Epoch 00010: val_accuracy did not improve from 0.58072\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.8616 - auc: 0.9474 - accuracy: 0.9380 - val_loss: 1.2130 - val_auc: 0.5582 - val_accuracy: 0.5112\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.8442 - auc: 0.9480 - accuracy: 0.9377\n",
      "Epoch 00011: val_accuracy did not improve from 0.58072\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.8442 - auc: 0.9480 - accuracy: 0.9377 - val_loss: 0.9783 - val_auc: 0.5898 - val_accuracy: 0.5404\n",
      "Epoch 12/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.8089 - auc: 0.9510 - accuracy: 0.9377\n",
      "Epoch 00012: val_accuracy did not improve from 0.58072\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.8148 - auc: 0.9509 - accuracy: 0.9376 - val_loss: 0.8433 - val_auc: 0.5726 - val_accuracy: 0.5471\n",
      "Epoch 13/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.9542 - auc: 0.9407 - accuracy: 0.9270\n",
      "Epoch 00013: val_accuracy did not improve from 0.58072\n",
      "243/243 [==============================] - 12s 49ms/step - loss: 0.9511 - auc: 0.9408 - accuracy: 0.9271 - val_loss: 0.8137 - val_auc: 0.5661 - val_accuracy: 0.5135\n",
      "Epoch 14/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.9821 - auc: 0.9440 - accuracy: 0.9337\n",
      "Epoch 00014: val_accuracy did not improve from 0.58072\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.9824 - auc: 0.9440 - accuracy: 0.9337 - val_loss: 2.0729 - val_auc: 0.5615 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.2892 - auc: 0.9326 - accuracy: 0.9251\n",
      "Epoch 00015: val_accuracy did not improve from 0.58072\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 1.2892 - auc: 0.9326 - accuracy: 0.9251 - val_loss: 1.6651 - val_auc: 0.5612 - val_accuracy: 0.5022\n",
      "Epoch 16/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.2151 - auc: 0.9440 - accuracy: 0.9346\n",
      "Epoch 00016: val_accuracy did not improve from 0.58072\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 1.2151 - auc: 0.9440 - accuracy: 0.9346 - val_loss: 0.8896 - val_auc: 0.5803 - val_accuracy: 0.5426\n",
      "Epoch 17/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.9477 - auc: 0.9497 - accuracy: 0.9422\n",
      "Epoch 00017: val_accuracy did not improve from 0.58072\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.9477 - auc: 0.9497 - accuracy: 0.9422 - val_loss: 1.5792 - val_auc: 0.5525 - val_accuracy: 0.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 20516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: early stopping\n",
      "layer 1 - block14_sepconv1_bn - out of 6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_145432-34sije2y/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_145432-34sije2y/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.947699248790741\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9497175812721252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9422233700752258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 1.5792062282562256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.5524643659591675\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5022421479225159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601045910\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.7037172913551331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 613 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpretty-bush-88\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/34sije2y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_145830-gio8aqwr\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33micy-sound-89\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/gio8aqwr\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/gio8aqwr</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.4573 - auc: 0.8842 - accuracy: 0.8589\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55381, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_89.h5\n",
      "243/243 [==============================] - 16s 65ms/step - loss: 1.4573 - auc: 0.8842 - accuracy: 0.8589 - val_loss: 0.6823 - val_auc: 0.5956 - val_accuracy: 0.5538\n",
      "Epoch 2/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.5623 - auc: 0.9428 - accuracy: 0.9134\n",
      "Epoch 00002: val_accuracy did not improve from 0.55381\n",
      "243/243 [==============================] - 12s 49ms/step - loss: 0.5660 - auc: 0.9424 - accuracy: 0.9129 - val_loss: 0.7966 - val_auc: 0.6119 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.7556 - auc: 0.9379 - accuracy: 0.9159\n",
      "Epoch 00003: val_accuracy improved from 0.55381 to 0.56278, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_89.h5\n",
      "243/243 [==============================] - 14s 56ms/step - loss: 0.7556 - auc: 0.9379 - accuracy: 0.9159 - val_loss: 0.7053 - val_auc: 0.5993 - val_accuracy: 0.5628\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.5306 - auc: 0.9495 - accuracy: 0.9202\n",
      "Epoch 00004: val_accuracy improved from 0.56278 to 0.57623, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_89.h5\n",
      "243/243 [==============================] - 14s 59ms/step - loss: 0.5306 - auc: 0.9495 - accuracy: 0.9202 - val_loss: 0.7038 - val_auc: 0.5960 - val_accuracy: 0.5762\n",
      "Epoch 5/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.5511 - auc: 0.9506 - accuracy: 0.9270\n",
      "Epoch 00005: val_accuracy did not improve from 0.57623\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.5509 - auc: 0.9506 - accuracy: 0.9267 - val_loss: 0.7666 - val_auc: 0.5801 - val_accuracy: 0.5426\n",
      "Epoch 6/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.6376 - auc: 0.9477 - accuracy: 0.9248\n",
      "Epoch 00006: val_accuracy did not improve from 0.57623\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.6440 - auc: 0.9474 - accuracy: 0.9244 - val_loss: 0.7329 - val_auc: 0.5711 - val_accuracy: 0.5538\n",
      "Epoch 7/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.6552 - auc: 0.9432 - accuracy: 0.9235\n",
      "Epoch 00007: val_accuracy did not improve from 0.57623\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.6596 - auc: 0.9427 - accuracy: 0.9230 - val_loss: 0.8175 - val_auc: 0.5773 - val_accuracy: 0.5269\n",
      "Epoch 8/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.7845 - auc: 0.9395 - accuracy: 0.9169\n",
      "Epoch 00008: val_accuracy did not improve from 0.57623\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.7867 - auc: 0.9394 - accuracy: 0.9169 - val_loss: 0.8498 - val_auc: 0.5702 - val_accuracy: 0.5247\n",
      "Epoch 9/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.5344 - auc: 0.9568 - accuracy: 0.9393\n",
      "Epoch 00009: val_accuracy did not improve from 0.57623\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.5336 - auc: 0.9569 - accuracy: 0.9393 - val_loss: 0.7553 - val_auc: 0.5741 - val_accuracy: 0.5628\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.7615 - auc: 0.9387 - accuracy: 0.9208\n",
      "Epoch 00010: val_accuracy did not improve from 0.57623\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.7615 - auc: 0.9387 - accuracy: 0.9208 - val_loss: 0.8942 - val_auc: 0.5781 - val_accuracy: 0.5224\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.7273 - auc: 0.9497 - accuracy: 0.9340\n",
      "Epoch 00011: val_accuracy did not improve from 0.57623\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.7273 - auc: 0.9497 - accuracy: 0.9340 - val_loss: 0.8923 - val_auc: 0.5869 - val_accuracy: 0.5157\n",
      "Epoch 12/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.7532 - auc: 0.9463 - accuracy: 0.9284\n",
      "Epoch 00012: val_accuracy did not improve from 0.57623\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.7532 - auc: 0.9465 - accuracy: 0.9284 - val_loss: 1.0114 - val_auc: 0.5628 - val_accuracy: 0.5112\n",
      "Epoch 13/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.7498 - auc: 0.9503 - accuracy: 0.9337\n",
      "Epoch 00013: val_accuracy did not improve from 0.57623\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.7498 - auc: 0.9503 - accuracy: 0.9337 - val_loss: 1.1118 - val_auc: 0.5656 - val_accuracy: 0.5045\n",
      "Epoch 14/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.7980 - auc: 0.9458 - accuracy: 0.9336\n",
      "Epoch 00014: val_accuracy did not improve from 0.57623\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.7980 - auc: 0.9458 - accuracy: 0.9336 - val_loss: 0.9714 - val_auc: 0.5711 - val_accuracy: 0.5224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 21391\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014: early stopping\n",
      "layer 2 - block14_sepconv1_act - out of 6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_145830-gio8aqwr/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_145830-gio8aqwr/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.7980476021766663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9458163976669312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9335826635360718\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 0.9713630676269531\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.5710752606391907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5224215388298035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601046106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.6823498010635376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 505 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33micy-sound-89\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/gio8aqwr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_150146-1odeaoym\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msleek-cloud-90\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/1odeaoym\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/1odeaoym</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.3802 - auc: 0.9388 - accuracy: 0.8867\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_90.h5\n",
      "243/243 [==============================] - 16s 67ms/step - loss: 0.3796 - auc: 0.9388 - accuracy: 0.8870 - val_loss: 0.8544 - val_auc: 0.6277 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.2956 - auc: 0.9652 - accuracy: 0.9201\n",
      "Epoch 00002: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.2948 - auc: 0.9653 - accuracy: 0.9203 - val_loss: 0.9177 - val_auc: 0.6263 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.3027 - auc: 0.9642 - accuracy: 0.9257\n",
      "Epoch 00003: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.3022 - auc: 0.9643 - accuracy: 0.9256 - val_loss: 1.0051 - val_auc: 0.6027 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.2608 - auc: 0.9709 - accuracy: 0.9354\n",
      "Epoch 00004: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.2608 - auc: 0.9709 - accuracy: 0.9354 - val_loss: 1.1888 - val_auc: 0.5895 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.2677 - auc: 0.9723 - accuracy: 0.9377\n",
      "Epoch 00005: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.2682 - auc: 0.9721 - accuracy: 0.9373 - val_loss: 1.5170 - val_auc: 0.5818 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.2703 - auc: 0.9724 - accuracy: 0.9371\n",
      "Epoch 00006: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 49ms/step - loss: 0.2703 - auc: 0.9724 - accuracy: 0.9371 - val_loss: 1.5722 - val_auc: 0.5801 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.2807 - auc: 0.9707 - accuracy: 0.9399\n",
      "Epoch 00007: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 49ms/step - loss: 0.2796 - auc: 0.9708 - accuracy: 0.9402 - val_loss: 1.8675 - val_auc: 0.5873 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.2753 - auc: 0.9737 - accuracy: 0.9441\n",
      "Epoch 00008: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 49ms/step - loss: 0.2742 - auc: 0.9738 - accuracy: 0.9443 - val_loss: 1.8622 - val_auc: 0.5765 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.2488 - auc: 0.9764 - accuracy: 0.9450\n",
      "Epoch 00009: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.2486 - auc: 0.9764 - accuracy: 0.9449 - val_loss: 2.0402 - val_auc: 0.5647 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.2829 - auc: 0.9728 - accuracy: 0.9425\n",
      "Epoch 00010: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.2830 - auc: 0.9728 - accuracy: 0.9426 - val_loss: 1.9809 - val_auc: 0.5587 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.2357 - auc: 0.9780 - accuracy: 0.9498\n",
      "Epoch 00011: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.2357 - auc: 0.9780 - accuracy: 0.9498 - val_loss: 1.9915 - val_auc: 0.5500 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 22121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00011: early stopping\n",
      "layer 3 - block14_sepconv2 - out of 6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_150146-1odeaoym/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_150146-1odeaoym/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.23565533757209778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9779760837554932\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9498323202133179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 1.9915432929992676\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.5500411987304688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601046260\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.8543572425842285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 397 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msleek-cloud-90\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/1odeaoym\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_150420-1nzl7hfw\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvague-thunder-91\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/1nzl7hfw\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/1nzl7hfw</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 1.1335 - auc: 0.8017 - accuracy: 0.7813\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_91.h5\n",
      "243/243 [==============================] - 16s 68ms/step - loss: 1.1308 - auc: 0.8020 - accuracy: 0.7810 - val_loss: 0.7005 - val_auc: 0.5790 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.3803 - auc: 0.9226 - accuracy: 0.8598\n",
      "Epoch 00002: val_accuracy did not improve from 0.50000\n",
      "243/243 [==============================] - 13s 53ms/step - loss: 0.3803 - auc: 0.9226 - accuracy: 0.8598 - val_loss: 0.7044 - val_auc: 0.6000 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.4244 - auc: 0.9271 - accuracy: 0.8695\n",
      "Epoch 00003: val_accuracy improved from 0.50000 to 0.50673, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_91.h5\n",
      "243/243 [==============================] - 16s 64ms/step - loss: 0.4244 - auc: 0.9271 - accuracy: 0.8695 - val_loss: 0.6992 - val_auc: 0.6091 - val_accuracy: 0.5067\n",
      "Epoch 4/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.3747 - auc: 0.9415 - accuracy: 0.8868\n",
      "Epoch 00004: val_accuracy did not improve from 0.50673\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.3758 - auc: 0.9414 - accuracy: 0.8868 - val_loss: 0.7285 - val_auc: 0.6094 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.3217 - auc: 0.9542 - accuracy: 0.8995\n",
      "Epoch 00005: val_accuracy did not improve from 0.50673\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.3211 - auc: 0.9544 - accuracy: 0.8995 - val_loss: 0.7090 - val_auc: 0.6112 - val_accuracy: 0.5022\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.4930 - auc: 0.9301 - accuracy: 0.8839\n",
      "Epoch 00006: val_accuracy did not improve from 0.50673\n",
      "243/243 [==============================] - 13s 51ms/step - loss: 0.4930 - auc: 0.9301 - accuracy: 0.8839 - val_loss: 0.7204 - val_auc: 0.6156 - val_accuracy: 0.5022\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.4829 - auc: 0.9375 - accuracy: 0.8901\n",
      "Epoch 00007: val_accuracy improved from 0.50673 to 0.52466, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_91.h5\n",
      "243/243 [==============================] - 15s 63ms/step - loss: 0.4829 - auc: 0.9375 - accuracy: 0.8901 - val_loss: 0.6907 - val_auc: 0.6149 - val_accuracy: 0.5247\n",
      "Epoch 8/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.5336 - auc: 0.9293 - accuracy: 0.8895\n",
      "Epoch 00008: val_accuracy improved from 0.52466 to 0.57175, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_91.h5\n",
      "243/243 [==============================] - 15s 63ms/step - loss: 0.5336 - auc: 0.9293 - accuracy: 0.8895 - val_loss: 0.6792 - val_auc: 0.6092 - val_accuracy: 0.5717\n",
      "Epoch 9/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.3696 - auc: 0.9560 - accuracy: 0.9166\n",
      "Epoch 00009: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.3696 - auc: 0.9560 - accuracy: 0.9166 - val_loss: 0.6941 - val_auc: 0.6040 - val_accuracy: 0.5224\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.3370 - auc: 0.9591 - accuracy: 0.9177\n",
      "Epoch 00010: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 13s 53ms/step - loss: 0.3370 - auc: 0.9591 - accuracy: 0.9177 - val_loss: 0.6944 - val_auc: 0.6119 - val_accuracy: 0.5314\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.5471 - auc: 0.9297 - accuracy: 0.8915\n",
      "Epoch 00011: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.5471 - auc: 0.9297 - accuracy: 0.8915 - val_loss: 0.8202 - val_auc: 0.6163 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.5198 - auc: 0.9349 - accuracy: 0.8931\n",
      "Epoch 00012: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.5198 - auc: 0.9349 - accuracy: 0.8931 - val_loss: 0.7362 - val_auc: 0.6152 - val_accuracy: 0.5022\n",
      "Epoch 13/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.5079 - auc: 0.9415 - accuracy: 0.8998\n",
      "Epoch 00013: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.5079 - auc: 0.9415 - accuracy: 0.8998 - val_loss: 0.6826 - val_auc: 0.6113 - val_accuracy: 0.5605\n",
      "Epoch 14/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.4853 - auc: 0.9434 - accuracy: 0.9064\n",
      "Epoch 00014: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.4853 - auc: 0.9434 - accuracy: 0.9064 - val_loss: 0.7380 - val_auc: 0.6187 - val_accuracy: 0.5090\n",
      "Epoch 15/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.3444 - auc: 0.9635 - accuracy: 0.9260\n",
      "Epoch 00015: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.3444 - auc: 0.9635 - accuracy: 0.9260 - val_loss: 0.7120 - val_auc: 0.6151 - val_accuracy: 0.5247\n",
      "Epoch 16/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.3506 - auc: 0.9599 - accuracy: 0.9218\n",
      "Epoch 00016: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.3506 - auc: 0.9599 - accuracy: 0.9218 - val_loss: 0.7777 - val_auc: 0.6213 - val_accuracy: 0.5022\n",
      "Epoch 17/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.3823 - auc: 0.9563 - accuracy: 0.9181\n",
      "Epoch 00017: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 13s 53ms/step - loss: 0.3823 - auc: 0.9563 - accuracy: 0.9181 - val_loss: 0.7408 - val_auc: 0.6181 - val_accuracy: 0.5090\n",
      "Epoch 18/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.4321 - auc: 0.9511 - accuracy: 0.9136\n",
      "Epoch 00018: val_accuracy did not improve from 0.57175\n",
      "243/243 [==============================] - 13s 51ms/step - loss: 0.4303 - auc: 0.9514 - accuracy: 0.9140 - val_loss: 0.7347 - val_auc: 0.6123 - val_accuracy: 0.5202\n",
      "Epoch 00018: early stopping\n",
      "layer 4 - block14_sepconv2_bn - out of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 22698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_150420-1nzl7hfw/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_150420-1nzl7hfw/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 0.43031045794487\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9513779878616333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9139798879623413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 0.73468416929245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.612318754196167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5201793909072876\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601046515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.6791887283325195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 649 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mvague-thunder-91\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/1nzl7hfw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_150835-37yk9tcj\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meager-dragon-92\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/37yk9tcj\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/37yk9tcj</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 5.9716 - auc: 0.7434 - accuracy: 0.7436\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.52691, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_92.h5\n",
      "243/243 [==============================] - 17s 68ms/step - loss: 5.9716 - auc: 0.7434 - accuracy: 0.7436 - val_loss: 0.7634 - val_auc: 0.5823 - val_accuracy: 0.5269\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.3870 - auc: 0.8797 - accuracy: 0.8540\n",
      "Epoch 00002: val_accuracy did not improve from 0.52691\n",
      "243/243 [==============================] - 13s 53ms/step - loss: 1.3870 - auc: 0.8797 - accuracy: 0.8540 - val_loss: 1.5981 - val_auc: 0.5898 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 1.9460 - auc: 0.8607 - accuracy: 0.8486\n",
      "Epoch 00003: val_accuracy did not improve from 0.52691\n",
      "243/243 [==============================] - 13s 53ms/step - loss: 1.9397 - auc: 0.8612 - accuracy: 0.8491 - val_loss: 1.1206 - val_auc: 0.5967 - val_accuracy: 0.5045\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.3230 - auc: 0.9048 - accuracy: 0.8886\n",
      "Epoch 00004: val_accuracy did not improve from 0.52691\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 1.3230 - auc: 0.9048 - accuracy: 0.8886 - val_loss: 1.2078 - val_auc: 0.6057 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 2.1256 - auc: 0.8761 - accuracy: 0.8649\n",
      "Epoch 00005: val_accuracy did not improve from 0.52691\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 2.1467 - auc: 0.8745 - accuracy: 0.8641 - val_loss: 2.0391 - val_auc: 0.6071 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 2.1417 - auc: 0.8810 - accuracy: 0.8752\n",
      "Epoch 00006: val_accuracy did not improve from 0.52691\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 2.1417 - auc: 0.8810 - accuracy: 0.8752 - val_loss: 1.2803 - val_auc: 0.6085 - val_accuracy: 0.5067\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.5680 - auc: 0.9141 - accuracy: 0.9043\n",
      "Epoch 00007: val_accuracy improved from 0.52691 to 0.53363, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_92.h5\n",
      "243/243 [==============================] - 14s 58ms/step - loss: 1.5680 - auc: 0.9141 - accuracy: 0.9043 - val_loss: 1.0155 - val_auc: 0.6145 - val_accuracy: 0.5336\n",
      "Epoch 8/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.7014 - auc: 0.9073 - accuracy: 0.8941\n",
      "Epoch 00008: val_accuracy did not improve from 0.53363\n",
      "243/243 [==============================] - 13s 54ms/step - loss: 1.7014 - auc: 0.9073 - accuracy: 0.8941 - val_loss: 1.6690 - val_auc: 0.6141 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 1.5676 - auc: 0.9119 - accuracy: 0.9021\n",
      "Epoch 00009: val_accuracy improved from 0.53363 to 0.54260, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_92.h5\n",
      "243/243 [==============================] - 15s 60ms/step - loss: 1.5692 - auc: 0.9117 - accuracy: 0.9017 - val_loss: 0.9115 - val_auc: 0.6131 - val_accuracy: 0.5426\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.9998 - auc: 0.8943 - accuracy: 0.8861\n",
      "Epoch 00010: val_accuracy did not improve from 0.54260\n",
      "243/243 [==============================] - 13s 53ms/step - loss: 1.9998 - auc: 0.8943 - accuracy: 0.8861 - val_loss: 1.6569 - val_auc: 0.6159 - val_accuracy: 0.5045\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.4877 - auc: 0.9176 - accuracy: 0.9099\n",
      "Epoch 00011: val_accuracy did not improve from 0.54260\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 1.4877 - auc: 0.9176 - accuracy: 0.9099 - val_loss: 1.2495 - val_auc: 0.6140 - val_accuracy: 0.5202\n",
      "Epoch 12/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.9707 - auc: 0.9080 - accuracy: 0.9020\n",
      "Epoch 00012: val_accuracy did not improve from 0.54260\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 1.9707 - auc: 0.9080 - accuracy: 0.9020 - val_loss: 1.0105 - val_auc: 0.6047 - val_accuracy: 0.5090\n",
      "Epoch 13/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 2.0776 - auc: 0.9054 - accuracy: 0.9012\n",
      "Epoch 00013: val_accuracy did not improve from 0.54260\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 2.0776 - auc: 0.9054 - accuracy: 0.9012 - val_loss: 0.9452 - val_auc: 0.6164 - val_accuracy: 0.5336\n",
      "Epoch 14/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.9286 - auc: 0.9147 - accuracy: 0.9091\n",
      "Epoch 00014: val_accuracy did not improve from 0.54260\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 1.9286 - auc: 0.9147 - accuracy: 0.9091 - val_loss: 1.1772 - val_auc: 0.6184 - val_accuracy: 0.5426\n",
      "Epoch 15/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 1.8698 - auc: 0.9107 - accuracy: 0.9046\n",
      "Epoch 00015: val_accuracy did not improve from 0.54260\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 1.8622 - auc: 0.9110 - accuracy: 0.9050 - val_loss: 2.2845 - val_auc: 0.6169 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 2.6601 - auc: 0.8879 - accuracy: 0.8860\n",
      "Epoch 00016: val_accuracy improved from 0.54260 to 0.57623, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_92.h5\n",
      "243/243 [==============================] - 14s 57ms/step - loss: 2.6601 - auc: 0.8879 - accuracy: 0.8860 - val_loss: 0.8500 - val_auc: 0.6130 - val_accuracy: 0.5762\n",
      "Epoch 17/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 1.7134 - auc: 0.9245 - accuracy: 0.9196\n",
      "Epoch 00017: val_accuracy improved from 0.57623 to 0.57848, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_92.h5\n",
      "243/243 [==============================] - 14s 58ms/step - loss: 1.7106 - auc: 0.9246 - accuracy: 0.9197 - val_loss: 0.8662 - val_auc: 0.6151 - val_accuracy: 0.5785\n",
      "Epoch 18/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 3.0745 - auc: 0.8851 - accuracy: 0.8856\n",
      "Epoch 00018: val_accuracy did not improve from 0.57848\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 3.0745 - auc: 0.8851 - accuracy: 0.8856 - val_loss: 1.6630 - val_auc: 0.6121 - val_accuracy: 0.5269\n",
      "Epoch 19/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 2.0166 - auc: 0.9224 - accuracy: 0.9171\n",
      "Epoch 00019: val_accuracy improved from 0.57848 to 0.58744, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_92.h5\n",
      "243/243 [==============================] - 14s 59ms/step - loss: 2.0166 - auc: 0.9224 - accuracy: 0.9171 - val_loss: 0.8555 - val_auc: 0.6144 - val_accuracy: 0.5874\n",
      "Epoch 20/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 2.6830 - auc: 0.8973 - accuracy: 0.8946\n",
      "Epoch 00020: val_accuracy improved from 0.58744 to 0.59417, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_92.h5\n",
      "243/243 [==============================] - 14s 59ms/step - loss: 2.6830 - auc: 0.8973 - accuracy: 0.8946 - val_loss: 0.8309 - val_auc: 0.6168 - val_accuracy: 0.5942\n",
      "Epoch 21/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.8276 - auc: 0.9260 - accuracy: 0.9240\n",
      "Epoch 00021: val_accuracy did not improve from 0.59417\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 1.8276 - auc: 0.9260 - accuracy: 0.9240 - val_loss: 0.9286 - val_auc: 0.6106 - val_accuracy: 0.5673\n",
      "Epoch 22/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.8179 - auc: 0.9243 - accuracy: 0.9184\n",
      "Epoch 00022: val_accuracy did not improve from 0.59417\n",
      "243/243 [==============================] - 13s 54ms/step - loss: 1.8179 - auc: 0.9243 - accuracy: 0.9184 - val_loss: 1.5422 - val_auc: 0.6100 - val_accuracy: 0.5314\n",
      "Epoch 23/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 2.4007 - auc: 0.9101 - accuracy: 0.9059\n",
      "Epoch 00023: val_accuracy did not improve from 0.59417\n",
      "243/243 [==============================] - 13s 53ms/step - loss: 2.4091 - auc: 0.9100 - accuracy: 0.9056 - val_loss: 0.9243 - val_auc: 0.6048 - val_accuracy: 0.5852\n",
      "Epoch 24/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.9544 - auc: 0.9231 - accuracy: 0.9217\n",
      "Epoch 00024: val_accuracy did not improve from 0.59417\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 1.9544 - auc: 0.9231 - accuracy: 0.9217 - val_loss: 2.4403 - val_auc: 0.6152 - val_accuracy: 0.5045\n",
      "Epoch 25/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 2.7188 - auc: 0.9051 - accuracy: 0.9031\n",
      "Epoch 00025: val_accuracy did not improve from 0.59417\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 2.7188 - auc: 0.9051 - accuracy: 0.9031 - val_loss: 1.6235 - val_auc: 0.6070 - val_accuracy: 0.5202\n",
      "Epoch 26/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 2.2786 - auc: 0.9145 - accuracy: 0.9109\n",
      "Epoch 00026: val_accuracy did not improve from 0.59417\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 2.2729 - auc: 0.9147 - accuracy: 0.9110 - val_loss: 1.7484 - val_auc: 0.6083 - val_accuracy: 0.5291\n",
      "Epoch 27/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 2.5165 - auc: 0.9101 - accuracy: 0.9090\n",
      "Epoch 00027: val_accuracy did not improve from 0.59417\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 2.5165 - auc: 0.9101 - accuracy: 0.9090 - val_loss: 1.6131 - val_auc: 0.6059 - val_accuracy: 0.5448\n",
      "Epoch 28/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.7526 - auc: 0.9310 - accuracy: 0.9251\n",
      "Epoch 00028: val_accuracy did not improve from 0.59417\n",
      "243/243 [==============================] - 13s 53ms/step - loss: 1.7526 - auc: 0.9310 - accuracy: 0.9251 - val_loss: 0.9574 - val_auc: 0.5971 - val_accuracy: 0.5583\n",
      "Epoch 29/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 2.1865 - auc: 0.9196 - accuracy: 0.9163\n",
      "Epoch 00029: val_accuracy did not improve from 0.59417\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 2.1782 - auc: 0.9197 - accuracy: 0.9166 - val_loss: 1.0976 - val_auc: 0.5951 - val_accuracy: 0.5471\n",
      "Epoch 30/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 1.8657 - auc: 0.9284 - accuracy: 0.9239\n",
      "Epoch 00030: val_accuracy did not improve from 0.59417\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 1.8657 - auc: 0.9284 - accuracy: 0.9239 - val_loss: 1.3488 - val_auc: 0.6012 - val_accuracy: 0.5426\n",
      "Epoch 00030: early stopping\n",
      "layer 5 - block14_sepconv2_act - out of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 23607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20200925_150835-37yk9tcj/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20200925_150835-37yk9tcj/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           epoch 29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            loss 1.8657246828079224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             auc 0.9284474849700928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        accuracy 0.9239102602005005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_loss 1.3487622737884521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_auc 0.6011784076690674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_accuracy 0.5426008701324463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1601046929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_val_loss 0.7634111642837524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        val_auc \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          _step \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       _runtime \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     _timestamp \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1081 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33meager-dragon-92\u001b[0m: \u001b[34mhttps://wandb.ai/inbar_sh/MAFAT/runs/37yk9tcj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200925_151529-38dk9nf5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdainty-star-93\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inbar_sh/MAFAT\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/inbar_sh/MAFAT/runs/38dk9nf5\" target=\"_blank\">https://wandb.ai/inbar_sh/MAFAT/runs/38dk9nf5</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.3288 - auc: 0.9334 - accuracy: 0.8603\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50224, saving model to /content/gdrive/My Drive/Final Project ITC/MAFAT Challenge/Our notebooks/Inbar/saved_models/xception_93.h5\n",
      "243/243 [==============================] - 16s 68ms/step - loss: 0.3288 - auc: 0.9334 - accuracy: 0.8603 - val_loss: 0.6932 - val_auc: 0.5110 - val_accuracy: 0.5022\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.2175 - auc: 0.9724 - accuracy: 0.9198\n",
      "Epoch 00002: val_accuracy did not improve from 0.50224\n",
      "243/243 [==============================] - 13s 53ms/step - loss: 0.2175 - auc: 0.9724 - accuracy: 0.9198 - val_loss: 0.6933 - val_auc: 0.5110 - val_accuracy: 0.5022\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1925 - auc: 0.9772 - accuracy: 0.9277\n",
      "Epoch 00003: val_accuracy did not improve from 0.50224\n",
      "243/243 [==============================] - 13s 52ms/step - loss: 0.1925 - auc: 0.9772 - accuracy: 0.9277 - val_loss: 0.6933 - val_auc: 0.4913 - val_accuracy: 0.5022\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1812 - auc: 0.9797 - accuracy: 0.9345\n",
      "Epoch 00004: val_accuracy did not improve from 0.50224\n",
      "243/243 [==============================] - 13s 51ms/step - loss: 0.1812 - auc: 0.9797 - accuracy: 0.9345 - val_loss: 0.6933 - val_auc: 0.4935 - val_accuracy: 0.5022\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1763 - auc: 0.9796 - accuracy: 0.9378\n",
      "Epoch 00005: val_accuracy did not improve from 0.50224\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1763 - auc: 0.9796 - accuracy: 0.9378 - val_loss: 0.6933 - val_auc: 0.5065 - val_accuracy: 0.5022\n",
      "Epoch 6/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1718 - auc: 0.9807 - accuracy: 0.9389\n",
      "Epoch 00006: val_accuracy did not improve from 0.50224\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1721 - auc: 0.9806 - accuracy: 0.9389 - val_loss: 0.6933 - val_auc: 0.5084 - val_accuracy: 0.5022\n",
      "Epoch 7/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1653 - auc: 0.9821 - accuracy: 0.9389\n",
      "Epoch 00007: val_accuracy did not improve from 0.50224\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1663 - auc: 0.9818 - accuracy: 0.9386 - val_loss: 0.6934 - val_auc: 0.4774 - val_accuracy: 0.5022\n",
      "Epoch 8/100\n",
      "242/243 [============================>.] - ETA: 0s - loss: 0.1631 - auc: 0.9823 - accuracy: 0.9397\n",
      "Epoch 00008: val_accuracy did not improve from 0.50224\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1629 - auc: 0.9824 - accuracy: 0.9398 - val_loss: 0.6934 - val_auc: 0.4936 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1572 - auc: 0.9836 - accuracy: 0.9449\n",
      "Epoch 00009: val_accuracy did not improve from 0.50224\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1572 - auc: 0.9836 - accuracy: 0.9449 - val_loss: 0.6935 - val_auc: 0.4915 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1582 - auc: 0.9834 - accuracy: 0.9414\n",
      "Epoch 00010: val_accuracy did not improve from 0.50224\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.1582 - auc: 0.9834 - accuracy: 0.9414 - val_loss: 0.6935 - val_auc: 0.4916 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - ETA: 0s - loss: 0.1528 - auc: 0.9842 - accuracy: 0.9431\n",
      "Epoch 00011: val_accuracy did not improve from 0.50224\n",
      "243/243 [==============================] - 12s 51ms/step - loss: 0.1528 - auc: 0.9842 - accuracy: 0.9431 - val_loss: 0.6935 - val_auc: 0.4829 - val_accuracy: 0.5000\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "run_several_layers(\"Xception\", xception_last_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "METS94FoKvaf"
   },
   "source": [
    "## submissiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfqFOASHJ7td"
   },
   "outputs": [],
   "source": [
    "final_model_name = [\"vgg16_108.h5\", \"vgg16_109.h5\", \"vgg19_106.h5\", \"vgg19_107.h5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 955,
     "status": "error",
     "timestamp": 1601060952610,
     "user": {
      "displayName": "inbar shirizly",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhnltgYoViGgUmKPKbZWsy9g3xL4PnaUdJm0APLmNE=s64",
      "userId": "04186382058769434872"
     },
     "user_tz": -180
    },
    "id": "XblvRlf2LoMg",
    "outputId": "db9af3e8-32da-4549-85ff-d3a818d46272"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3aaa6a4481e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_model_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mfinal_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'callback'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_checkpoint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Creating DataFrame with the probability prediction for each segment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_model_name' is not defined"
     ]
    }
   ],
   "source": [
    "for model_name in final_model_name:\n",
    "  final_model_path = model_input['callback']['model_checkpoint']['file_path'] + \"/\" + model_name\n",
    "  final_model = tf.keras.models.load_model(final_model_path)\n",
    "\n",
    "  # Creating DataFrame with the probability prediction for each segment\n",
    "  submission =  pd.DataFrame()\n",
    "  submission['segment_id'] = test_df['segment_id']\n",
    "  submission['prediction'] = final_model.predict(test_x)\n",
    "  submission['prediction'] = submission['prediction'].astype('float')\n",
    "\n",
    "  # Save submission\n",
    "  submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "  submission_file_name = model_name.split(\".\")[0] + \".zip\"\n",
    "\n",
    "  # Download zip file\n",
    "  from zipfile import ZipFile\n",
    "  from google.colab import files\n",
    "\n",
    "  with ZipFile(submission_file_name, 'w') as myzip:\n",
    "    myzip.write('submission.csv')\n",
    "\n",
    "  files.download(submission_file_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "uOfXzmPYK24k",
    "5sgS5HnELtdt",
    "mj7Trcp2OMd-",
    "8P-iesBx4R2I",
    "f2r9f_apK4st",
    "Ojz-gt2omPuf",
    "asux4JnPmLPH",
    "yAJR55BHmqnH"
   ],
   "name": "Transfer learning.ipynb",
   "provenance": [
    {
     "file_id": "1SkoA3wQ_3cYtxt3P5pF-DSB-MFGGRQnN",
     "timestamp": 1597302243583
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
